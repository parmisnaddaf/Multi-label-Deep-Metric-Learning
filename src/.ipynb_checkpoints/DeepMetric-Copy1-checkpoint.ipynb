{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mydatasets\n",
    "import mymodels\n",
    "import utils\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import json \n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics._ranking import _binary_clf_curve, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3958</th>\n",
       "      <th>3959</th>\n",
       "      <th>3960</th>\n",
       "      <th>3961</th>\n",
       "      <th>3962</th>\n",
       "      <th>3963</th>\n",
       "      <th>3964</th>\n",
       "      <th>3965</th>\n",
       "      <th>3966</th>\n",
       "      <th>3967</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRR1166318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR176810</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR181956</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR2100379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR671746</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR1146372</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR176477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR1049074</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR867528</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7960 rows × 3967 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "0                                                                       ...   \n",
       "SRR1166318     0     0     1     0     0     4     0     0     0     1  ...   \n",
       "ERR176810      0     0     1     0     2     3     0     0     0     1  ...   \n",
       "ERR181956      0     0     1     0     1     3     1     0     0     1  ...   \n",
       "SRR2100379     0     0     1     0     0     4     1     0     0     1  ...   \n",
       "SRR924706      0     0     1     0     2     3     0     0     0     1  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "SRR671746      0     0     1     0     0     3     0     0     0     1  ...   \n",
       "SRR1146372     0     0     2     0     0     3     0     0     0     1  ...   \n",
       "ERR176477      0     0     1     0     1     3     0     0     0     1  ...   \n",
       "SRR1049074     0     0     1     0     0     4     0     0     0     1  ...   \n",
       "ERR867528      0     0     2     0     2     3     0     0     0     2  ...   \n",
       "\n",
       "            3958  3959  3960  3961  3962  3963  3964  3965  3966  3967  \n",
       "0                                                                       \n",
       "SRR1166318     0     0     1     1     0     0     0     0     0     0  \n",
       "ERR176810      0     0     0     1     0     0     0     0     0     0  \n",
       "ERR181956      0     0     0     0     0     0     0     0     0     0  \n",
       "SRR2100379     0     0     0     0     0     0     0     0     0     0  \n",
       "SRR924706      0     0     0     0     0     0     0     0     0     0  \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "SRR671746      0     0     0     0     0     0     0     0     0     0  \n",
       "SRR1146372     0     0     0     0     0     0     0     0     0     0  \n",
       "ERR176477      0     0     0     0     0     0     0     0     0     0  \n",
       "SRR1049074     0     1     0     0     0     0     0     0     0     0  \n",
       "ERR867528      0     0     0     1     0     0     0     0     0     0  \n",
       "\n",
       "[7960 rows x 3967 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('../data/gene_data.csv', header=None, index_col=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amikacin</th>\n",
       "      <th>capreomycin</th>\n",
       "      <th>ciprofloxacin</th>\n",
       "      <th>ethambutol</th>\n",
       "      <th>ethionamide</th>\n",
       "      <th>isoniazid</th>\n",
       "      <th>kanamycin</th>\n",
       "      <th>moxifloxacin</th>\n",
       "      <th>ofloxacin</th>\n",
       "      <th>pyrazinamide</th>\n",
       "      <th>rifampicin</th>\n",
       "      <th>streptomycin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRR3675211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3675215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3675217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3675218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3675224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924705</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924706</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924707</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924708</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924709</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7845 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            amikacin  capreomycin  ciprofloxacin  ethambutol  ethionamide  \\\n",
       "id                                                                          \n",
       "SRR3675211       NaN          NaN            NaN         0.0          NaN   \n",
       "SRR3675215       NaN          NaN            NaN         0.0          NaN   \n",
       "SRR3675217       NaN          NaN            NaN         1.0          NaN   \n",
       "SRR3675218       NaN          NaN            NaN         1.0          NaN   \n",
       "SRR3675224       NaN          NaN            NaN         0.0          NaN   \n",
       "...              ...          ...            ...         ...          ...   \n",
       "SRR924705        NaN          0.0            NaN         0.0          0.0   \n",
       "SRR924706        NaN          0.0            NaN         0.0          0.0   \n",
       "SRR924707        NaN          0.0            NaN         0.0          0.0   \n",
       "SRR924708        NaN          0.0            NaN         0.0          0.0   \n",
       "SRR924709        NaN          0.0            NaN         0.0          0.0   \n",
       "\n",
       "            isoniazid  kanamycin  moxifloxacin  ofloxacin  pyrazinamide  \\\n",
       "id                                                                        \n",
       "SRR3675211        0.0        NaN           NaN        NaN           0.0   \n",
       "SRR3675215        0.0        NaN           NaN        NaN           0.0   \n",
       "SRR3675217        1.0        NaN           NaN        NaN           0.0   \n",
       "SRR3675218        1.0        NaN           NaN        NaN           1.0   \n",
       "SRR3675224        0.0        NaN           NaN        NaN           0.0   \n",
       "...               ...        ...           ...        ...           ...   \n",
       "SRR924705         0.0        0.0           NaN        0.0           0.0   \n",
       "SRR924706         0.0        0.0           NaN        0.0           0.0   \n",
       "SRR924707         0.0        0.0           NaN        0.0           0.0   \n",
       "SRR924708         0.0        0.0           NaN        0.0           0.0   \n",
       "SRR924709         0.0        0.0           NaN        0.0           0.0   \n",
       "\n",
       "            rifampicin  streptomycin  \n",
       "id                                    \n",
       "SRR3675211         0.0           NaN  \n",
       "SRR3675215         0.0           NaN  \n",
       "SRR3675217         1.0           NaN  \n",
       "SRR3675218         0.0           NaN  \n",
       "SRR3675224         0.0           NaN  \n",
       "...                ...           ...  \n",
       "SRR924705          0.0           0.0  \n",
       "SRR924706          0.0           0.0  \n",
       "SRR924707          0.0           0.0  \n",
       "SRR924708          0.0           0.0  \n",
       "SRR924709          0.0           0.0  \n",
       "\n",
       "[7845 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.read_csv('../data/AllLabels.csv', index_col='id')\n",
    "Y = Y[Y.index.isin(X.index)]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs with no Y found: 115\n"
     ]
    }
   ],
   "source": [
    "NoYs = X[np.logical_not(X.index.isin(Y.index))]\n",
    "print('Xs with no Y found:', NoYs.shape[0])\n",
    "X = X.drop(NoYs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sort_index().reset_index().rename(columns={0: 'id'})\n",
    "Y = Y.sort_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat = X.iloc[:, 1:].to_numpy()\n",
    "Y_mat = Y.iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Count: 6277\n",
      "Validation Count: 784\n",
      "Test Count: 784\n"
     ]
    }
   ],
   "source": [
    "val_test_count = int(X_mat.shape[0] * 0.1)\n",
    "val_test_indcs = (np.random.permutation(X_mat.shape[0])[:2*val_test_count]).reshape((2, -1))\n",
    "\n",
    "X_val = X_mat[val_test_indcs[0], :]\n",
    "Y_val = Y_mat[val_test_indcs[0], :]\n",
    "\n",
    "X_test = X_mat[val_test_indcs[1], :]\n",
    "Y_test = Y_mat[val_test_indcs[1], :]\n",
    "\n",
    "X_train = np.delete(X_mat, val_test_indcs.flatten(), axis=0)\n",
    "Y_train = np.delete(Y_mat, val_test_indcs.flatten(), axis=0)\n",
    "print(f'Train Count: {X_train.shape[0]}')\n",
    "print(f'Validation Count: {X_val.shape[0]}')\n",
    "print(f'Test Count: {X_test.shape[0]}')\n",
    "\n",
    "shuffle_indcs = np.random.permutation(X_train.shape[0])\n",
    "X_train = X_train[shuffle_indcs, :]\n",
    "Y_train = Y_train[shuffle_indcs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc(x_train: np.ndarray, y_train: np.ndarray, x_eval: np.ndarray, y_eval: np.ndarray, model, n_neighbors=5, model_name=\"FC\"):\n",
    "    if model_name == \"LRCN\":\n",
    "\n",
    "        xx_train, yy_train, fs = prepare_data(x_train, y_train)\n",
    "        xx_test, yy_test, fs = prepare_data(x_eval, y_eval)\n",
    "        emb_train = model(torch.from_numpy(xx_train.astype('float32'))).detach().numpy()\n",
    "        emb_test = model(torch.from_numpy(xx_test.astype('float32'))).detach().numpy()\n",
    "    else:\n",
    "        emb_train = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n",
    "        emb_val = model(torch.from_numpy(x_eval.astype('float32'))).detach().numpy()   \n",
    "\n",
    "    KNN = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto').fit(emb_train)\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_val)\n",
    "    y_k_neghbors = y_train[nbr_indcs, :]\n",
    "    y_pred = np.nanmean(y_k_neghbors, axis=1)\n",
    "    y_pred[np.where(np.isnan(y_pred))] = 0.5\n",
    "    #y_pred = np.round(y_pred)\n",
    "\n",
    "    condition = np.where(np.logical_and(np.logical_not(np.isnan(y_eval)), np.logical_not(np.isnan(y_pred))))\n",
    "\n",
    "    #### CALCULATE ROC\n",
    "\n",
    "    #return np.sum(y_pred[condition] == y_eval[condition]) / y_eval[condition].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(x_train: np.ndarray, y_train: np.ndarray, x_eval: np.ndarray, y_eval: np.ndarray, model, n_neighbors=5, model_name=\"FC\"):\n",
    "    if model_name == \"LRCN\":\n",
    "\n",
    "        xx_train, yy_train, fs = prepare_data(x_train, y_train)\n",
    "        xx_test, yy_test, fs = prepare_data(x_eval, y_eval)\n",
    "        emb_train = model(torch.from_numpy(xx_train.astype('float32'))).detach().numpy()\n",
    "        emb_val = model(torch.from_numpy(xx_test.astype('float32'))).detach().numpy()\n",
    "        print(xx_train.shape)\n",
    "        print(emb_train.shape)\n",
    "    else:\n",
    "        emb_train = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n",
    "        emb_val = model(torch.from_numpy(x_eval.astype('float32'))).detach().numpy() \n",
    "        \n",
    "        \n",
    "    KNN = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto').fit(emb_train)\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_val)\n",
    "    y_k_neghbors = y_train[nbr_indcs, :] #y_eval x 5 x 12\n",
    "    y_pred = np.nanmean(y_k_neghbors, axis=1) #y_eval x 12\n",
    "    y_pred = np.round(y_pred) #0.5 > --> 1\n",
    "\n",
    "    condition = np.where(np.logical_and(np.logical_not(np.isnan(y_eval)), np.logical_not(np.isnan(y_pred))))\n",
    "\n",
    "    return np.sum(y_pred[condition] == y_eval[condition]) / y_eval[condition].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_Score(model, X_test, Y_test,X_train, Y_train, limited=False, model_name = \"FC\"):\n",
    "    num_of_drugs = 12\n",
    "    \n",
    "    if model_name == \"LRCN\":\n",
    "\n",
    "        xx_train, yy_train, fs = prepare_data(X_train, Y_train)\n",
    "        xx_test, yy_test, fs = prepare_data(X_test, Y_test)\n",
    "        emb_train = model(torch.from_numpy(xx_train.astype('float32'))).detach().numpy()\n",
    "        emb_test = model(torch.from_numpy(xx_test.astype('float32'))).detach().numpy()\n",
    "    else:\n",
    "        emb_train = model(torch.from_numpy(X_train.astype('float32'))).detach().numpy()\n",
    "        emb_test = model(torch.from_numpy(X_test.astype('float32'))).detach().numpy() \n",
    "        \n",
    "    KNN = NearestNeighbors(n_neighbors=5, algorithm='auto').fit(emb_train)\n",
    "\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_test)\n",
    "    y_k_neghbors = Y_train[nbr_indcs, :] #y_eval x 5 x 12\n",
    "    y_pred_keras_tmp = np.nanmean(y_k_neghbors, axis=1) #y_eval x 1\n",
    "    \n",
    "    condition_nan =  np.where(np.isnan(y_pred_keras_tmp))\n",
    "    y_pred_keras_tmp[condition_nan] = 0.5\n",
    "    \n",
    "    condition = np.where(np.isnan(Y_test))\n",
    "    Y_test[condition] = -1\n",
    "    print(Y_test)\n",
    "\n",
    "    \n",
    "    for i in range(0, num_of_drugs):\n",
    "        y_test_tmp = Y_test[:, i]\n",
    "        y_pred_keras = y_pred_keras_tmp[:, i]\n",
    "        i2 = 0\n",
    "        while i2 < len(y_test_tmp):\n",
    "            if y_test_tmp[i2] != 0 and y_test_tmp[i2] != 1:\n",
    "                y_test_tmp = np.delete(y_test_tmp, i2)\n",
    "                y_pred_keras = np.delete(y_pred_keras, i2)\n",
    "            else:\n",
    "                i2 = i2 + 1\n",
    "    y_test_tmp = []\n",
    "    y_pred_keras = []\n",
    "    for i in range(0, num_of_drugs):\n",
    "        y_test_tmp.extend(Y_test[:, i])\n",
    "        y_pred_keras.extend(y_pred_keras_tmp[:, i])\n",
    "    i = 0\n",
    "    while i < len(y_test_tmp):\n",
    "        if y_test_tmp[i] != 0 and y_test_tmp[i] != 1:\n",
    "            y_test_tmp = np.delete(y_test_tmp, i)\n",
    "            y_pred_keras = np.delete(y_pred_keras, i)\n",
    "        else:\n",
    "            i = i + 1\n",
    "    fpr_keras, tpr_keras, _ = roc_curve(y_test_tmp, y_pred_keras)\n",
    "    # print(\"___\")\n",
    "    # print(fpr_keras)\n",
    "    # print(\"___\")\n",
    "    # print(tpr_keras)\n",
    "    # print(\"___\")\n",
    "    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "    # print(auc_keras)\n",
    "    return auc_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC(model, X_test, y_test, X_train, Y_train, name, multi=False, limited=False, bccdc=False, model_name = \"FC\"):\n",
    "    \n",
    "    num_of_drugs = 12\n",
    "    if model_name == \"LRCN\":\n",
    "\n",
    "        xx_train, yy_train, fs = prepare_data(X_train, Y_train)\n",
    "        xx_test, yy_test, fs = prepare_data(X_test, Y_test)\n",
    "        emb_train = model(torch.from_numpy(xx_train.astype('float32'))).detach().numpy()\n",
    "        emb_test = model(torch.from_numpy(xx_test.astype('float32'))).detach().numpy()\n",
    "    else:\n",
    "        emb_train = model(torch.from_numpy(X_train.astype('float32'))).detach().numpy()\n",
    "        emb_test = model(torch.from_numpy(X_test.astype('float32'))).detach().numpy() \n",
    "    \n",
    "\n",
    "    KNN = NearestNeighbors(n_neighbors=5, algorithm='auto').fit(emb_train)\n",
    "\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_test)\n",
    "    y_k_neghbors = Y_train[nbr_indcs, :] #y_eval x 5 x 12\n",
    "    y_pred_keras_tmp = np.nanmean(y_k_neghbors, axis=1) #y_eval x 1\n",
    "    \n",
    "    condition_nan =  np.where(np.isnan(y_pred_keras_tmp))\n",
    "    y_pred_keras_tmp[condition_nan] = 0.5\n",
    "    \n",
    "    condition = np.where(np.isnan(Y_test))\n",
    "    Y_test[condition] = -1\n",
    "    print(Y_test)    \n",
    "    \n",
    "    y_pred_keras = []\n",
    "    y_test_tmp = []\n",
    "    scores = []\n",
    "    if limited:\n",
    "        num_of_drugs = 7\n",
    "\n",
    "\n",
    "    if bccdc:\n",
    "        num_of_drugs = 5\n",
    "\n",
    "        tmp_b = []\n",
    "        for i in range(0, len(y_pred_keras_tmp)):\n",
    "            tmp_b_b = [y_pred_keras_tmp[i][0], y_pred_keras_tmp[i][1], y_pred_keras_tmp[i][2], y_pred_keras_tmp[i][6],\n",
    "                       y_pred_keras_tmp[i][8]]\n",
    "            tmp_b.append(tmp_b_b)\n",
    "\n",
    "        y_pred_keras_tmp = np.array(tmp_b)\n",
    "\n",
    "    if multi == False:\n",
    "        for i in range(0, len(y_pred_keras_tmp)):\n",
    "            y_pred_keras.append(y_pred_keras_tmp[i][1])\n",
    "            y_test_tmp.append(y_test[i][1])\n",
    "        ROC_maker(y_test_tmp, y_pred_keras, name)\n",
    "    else:\n",
    "        for i in range(0, num_of_drugs):  # len(y_test[0])):\n",
    "            y_test_tmp = y_test[:, i]\n",
    "            y_pred_keras = y_pred_keras_tmp[:, i]\n",
    "            # bug? cahnge i2 to i\n",
    "            i2 = 0\n",
    "            while i2 < len(y_test_tmp):\n",
    "                if y_test_tmp[i2] != 0 and y_test_tmp[i2] != 1:\n",
    "                    y_test_tmp = np.delete(y_test_tmp, i2)\n",
    "                    y_pred_keras = np.delete(y_pred_keras, i2)\n",
    "                else:\n",
    "                    i2 = i2 + 1\n",
    "            try:\n",
    "                # print(len(y_test_tmp))\n",
    "                # print(len(y_test_tmp[0]))\n",
    "                # print(len(y_pred_keras))\n",
    "                # print(len(y_pred_keras[0]))\n",
    "                if i != 0:\n",
    "                    if i < num_of_drugs - 1:\n",
    "                        scores.append(ROC_maker(y_test_tmp, y_pred_keras, name + \" _ \" + str(i), False, False))\n",
    "                    else:\n",
    "                        scores.append(ROC_maker(y_test_tmp, y_pred_keras, name + \" _ \" + str(i), False, True))\n",
    "                else:\n",
    "                    scores.append(ROC_maker(y_test_tmp, y_pred_keras, name + \" _ \" + str(i), True, False))\n",
    "\n",
    "            except():\n",
    "                print(\"error on \" + i + \" \" + y_test_tmp)\n",
    "        y_test_tmp = []\n",
    "        y_pred_keras = []\n",
    "        for i in range(0, num_of_drugs):  # len(y_test[0])):\n",
    "            y_test_tmp.extend(y_test[:, i])\n",
    "            # print(y_test_tmp)\n",
    "            y_pred_keras.extend(y_pred_keras_tmp[:, i])\n",
    "        i = 0\n",
    "        while i < len(y_test_tmp):\n",
    "            if y_test_tmp[i] != 0 and y_test_tmp[i] != 1:\n",
    "                y_test_tmp = np.delete(y_test_tmp, i)\n",
    "                y_pred_keras = np.delete(y_pred_keras, i)\n",
    "            else:\n",
    "                i = i + 1\n",
    "        ROC_maker(y_test_tmp, y_pred_keras, name + \" _ All\", True)\n",
    "        # fpr_keras, tpr_keras, _ = roc_curve(y_test_tmp, y_pred_keras)\n",
    "        # auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        # print(auc_keras)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_recall_calculator(y_true, probas_pred, pos_label=None,\n",
    "                                  sample_weight=None):\n",
    "    fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n",
    "                                             pos_label=pos_label,\n",
    "                                             sample_weight=sample_weight)\n",
    "\n",
    "    specificity = (fps[-1] - fps) / fps[-1]\n",
    "    specificity[np.isnan(specificity)] = 0\n",
    "    recall = tps / tps[-1]\n",
    "\n",
    "    # stop when full recall attained\n",
    "    # and reverse the outputs so recall is decreasing\n",
    "    last_ind = tps.searchsorted(tps[-1])\n",
    "    sl = slice(last_ind, None, -1)\n",
    "    return np.r_[specificity[sl], 1], np.r_[recall[sl], 0], thresholds[sl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR_maker(y_test_tmp, y_pred_keras):\n",
    "    specificity, recall, th = specificity_recall_calculator(y_test_tmp, y_pred_keras)\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_test_tmp, y_pred_keras)\n",
    "    score = 0\n",
    "    count = 0\n",
    "    for i in range(0 ,len(recall)):\n",
    "        if specificity[i] == 0.95:\n",
    "            score += recall[i]\n",
    "            count += count + 1\n",
    "\n",
    "    if score != 0:\n",
    "        return (score/count), auc(lr_recall, lr_precision)\n",
    "\n",
    "    for i in range(0 ,len(recall)):\n",
    "        if specificity[i] <= 0.952 and specificity[i] >= 0.945:\n",
    "            score += recall[i]\n",
    "            count += 1\n",
    "\n",
    "    if score != 0:\n",
    "        return (score/count), auc(lr_recall, lr_precision)\n",
    "\n",
    "    for i in range(0, len(recall)):\n",
    "        if specificity[i] <= 0.955 and specificity[i] >= 0.940:\n",
    "            score += recall[i]\n",
    "            count += 1\n",
    "    if score != 0:\n",
    "        return (score / count), auc(lr_recall, lr_precision)\n",
    "    else:\n",
    "        return 0, auc(lr_recall, lr_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PR(model, X_test, y_test, X_train, Y_train, bccdc=False, model_name=\"FC\"):\n",
    "    num_of_drugs = 12\n",
    "    if model_name == \"LRCN\":\n",
    "\n",
    "        xx_train, yy_train, fs = prepare_data(X_train, Y_train)\n",
    "        xx_test, yy_test, fs = prepare_data(X_test, Y_test)\n",
    "        emb_train = model(torch.from_numpy(xx_train.astype('float32'))).detach().numpy()\n",
    "        emb_test = model(torch.from_numpy(xx_test.astype('float32'))).detach().numpy()\n",
    "    else:\n",
    "        emb_train = model(torch.from_numpy(X_train.astype('float32'))).detach().numpy()\n",
    "        emb_test = model(torch.from_numpy(X_test.astype('float32'))).detach().numpy()        \n",
    "        \n",
    "    KNN = NearestNeighbors(n_neighbors=5, algorithm='auto').fit(emb_train)\n",
    "\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_test)\n",
    "    y_k_neghbors = Y_train[nbr_indcs, :] #y_eval x 5 x 12\n",
    "    y_pred_keras_tmp = np.nanmean(y_k_neghbors, axis=1) #y_eval x 1\n",
    "    \n",
    "    condition_nan =  np.where(np.isnan(y_pred_keras_tmp))\n",
    "    y_pred_keras_tmp[condition_nan] = 0.5\n",
    "    \n",
    "    condition = np.where(np.isnan(Y_test))\n",
    "    Y_test[condition] = -1\n",
    "\n",
    "    y_pred_keras = []\n",
    "    y_test_tmp = []\n",
    "    scores_sr = []\n",
    "    scores_pr = []\n",
    "\n",
    "    if bccdc:\n",
    "        num_of_drugs = 5\n",
    "\n",
    "        tmp_b = []\n",
    "        for i in range(0, len(y_pred_keras_tmp)):\n",
    "            tmp_b_b = [y_pred_keras_tmp[i][0], y_pred_keras_tmp[i][1], y_pred_keras_tmp[i][2], y_pred_keras_tmp[i][6],\n",
    "                       y_pred_keras_tmp[i][8]]\n",
    "            tmp_b.append(tmp_b_b)\n",
    "\n",
    "        y_pred_keras_tmp = np.array(tmp_b)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0, num_of_drugs):  # len(y_test[0])):\n",
    "        y_test_tmp = y_test[:, i]\n",
    "        y_pred_keras = y_pred_keras_tmp[:, i]\n",
    "        i2 = 0\n",
    "        while i2 < len(y_test_tmp):\n",
    "            if y_test_tmp[i2] != 0 and y_test_tmp[i2] != 1:\n",
    "                y_test_tmp = np.delete(y_test_tmp, i2)\n",
    "                y_pred_keras = np.delete(y_pred_keras, i2)\n",
    "            else:\n",
    "                i2 = i2 + 1\n",
    "        try:\n",
    "            if i != 0:\n",
    "                if i < num_of_drugs - 1:\n",
    "                    sr, pr = SR_maker(y_test_tmp, y_pred_keras)\n",
    "                    scores_sr.append(sr)\n",
    "                    scores_pr.append(pr)\n",
    "                else:\n",
    "                    sr, pr = SR_maker(y_test_tmp, y_pred_keras)\n",
    "                    scores_sr.append(sr)\n",
    "                    scores_pr.append(pr)\n",
    "            else:\n",
    "                sr, pr = SR_maker(y_test_tmp, y_pred_keras)\n",
    "                scores_sr.append(sr)\n",
    "                scores_pr.append(pr)\n",
    "\n",
    "        except():\n",
    "            print(\"error on \" + i + \" \" + y_test_tmp)\n",
    "    return scores_sr, scores_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_maker(y_test_tmp, y_pred_keras, name, clear=True, save=True):\n",
    "    # print(y_test_tmp)\n",
    "    fpr_keras, tpr_keras, _ = roc_curve(y_test_tmp, y_pred_keras)\n",
    "    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "    if clear:\n",
    "        plt.clf()\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve _ ' + name)\n",
    "    plt.legend(loc='best')\n",
    "    fig1 = plt.gcf()\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "    # if save:\n",
    "    #     fig1.savefig('result/ROC_' + name + '.png', dpi=100)\n",
    "    return auc_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        self.drop2 = nn.Dropout(0.1)\n",
    "        self.drop3 = nn.Dropout(0.1)\n",
    "        self.conv1 = nn.Conv1d(in_channels=20, out_channels=8, kernel_size=3, padding = 'same')\n",
    "        self.act = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 4, kernel_size=6, padding = 'same')\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4, stride=4, padding=1)\n",
    "        self.lstm1 = nn.LSTM(input_size=4, hidden_size=518, batch_first=True, num_layers=3, dropout=0.1)\n",
    "        self.lstm2 = nn.LSTM(input_size=518, hidden_size=64, batch_first=True, num_layers=3, dropout=0.1)\n",
    "        self.dense1 = nn.Linear(64, 64)\n",
    "        self.dense2= nn.Linear(64, 518)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.drop1(x)\n",
    "        x = self.conv1(x.permute(0,2,1))\n",
    "        x = self.act(x)  \n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool2(x)\n",
    "        x , h  = self.lstm1(x.permute(0,2,1))\n",
    "        x = self.drop1(x)\n",
    "        x , h = self.lstm2(x)\n",
    "        x = self.drop2(x[:,-1,:])\n",
    "        # x = x.reshape(x.size(0), -1)\n",
    "        x = self.act(self.dense1(x))\n",
    "        x = self.drop3(x)\n",
    "        x = self.act(self.dense2(x))\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def prepare_data(features, label):\n",
    "    # TODO\n",
    "    FrameSize = 200\n",
    "    X = features.tolist()\n",
    "    y = label.tolist()\n",
    "\n",
    "    for i in range(0, len(X)):\n",
    "        if len(X[i]) < ((len(X[i]) // FrameSize + 1) * FrameSize):\n",
    "            for j in range(0, (((len(X[i]) // FrameSize + 1) * FrameSize) - len(X[i]))):\n",
    "                X[i].append(0)\n",
    "        X[i] = np.reshape(X[i], (FrameSize, len(X[i]) // FrameSize))\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y, FrameSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss_function(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, -1), K.floatx())\n",
    "    return K.binary_crossentropy(y_true * mask, y_pred * mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 (0, 20, 0.001, 100, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pnaddaf/anaconda3/envs/env/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/localhome/pnaddaf/anaconda3/envs/env/lib/python3.7/site-packages/torch/nn/modules/conv.py:295: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/aten/src/ATen/native/Convolution.cpp:660.)\n",
      "  self.padding, self.dilation, self.groups)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 64 , Loss value : 0.056586735\n",
      "Batch size : 125 , Loss value : 0.043698546\n",
      "Batch size : 127 , Loss value : 0.057241626\n",
      "Batch size : 116 , Loss value : 0.03951424\n",
      "Batch size : 96 , Loss value : 0.031338412\n",
      "Batch size : 28 , Loss value : 0.031039173\n",
      "Batch size : 74 , Loss value : 0.03489475\n",
      "Batch size : 100 , Loss value : 0.02578783\n",
      "Batch size : 340 , Loss value : 0.04487355\n",
      "Batch size : 102 , Loss value : 0.027135564\n",
      "Batch size : 39 , Loss value : 0.027695369\n",
      "Batch size : 95 , Loss value : 0.02431876\n",
      "Batch size : 19 , Loss value : 0.027224993\n",
      "Batch size : 50 , Loss value : 0.019829215\n",
      "Batch size : 30 , Loss value : 0.02405803\n",
      "Batch size : 12 , Loss value : 0.02492739\n",
      "Batch size : 49 , Loss value : 0.037824232\n",
      "Batch size : 21 , Loss value : 0.027958496\n",
      "Batch size : 8 , Loss value : 0.023621978\n",
      "Batch size : 79 , Loss value : 0.030943243\n",
      "Batch size : 66 , Loss value : 0.026013298\n",
      "Batch size : 256 , Loss value : 0.037321955\n",
      "Batch size : 197 , Loss value : 0.03235276\n",
      "Batch size : 32 , Loss value : 0.0324936\n",
      "Batch size : 310 , Loss value : 0.025887521\n",
      "Batch size : 37 , Loss value : 0.015562858\n",
      "Batch size : 67 , Loss value : 0.033623967\n",
      "Batch size : 60 , Loss value : 0.02377066\n",
      "Batch size : 20 , Loss value : 0.024034742\n",
      "Batch size : 254 , Loss value : 0.022121415\n",
      "Batch size : 148 , Loss value : 0.019440182\n",
      "Batch size : 89 , Loss value : 0.02005925\n",
      "Batch size : 66 , Loss value : 0.022521975\n",
      "Batch size : 53 , Loss value : 0.01863498\n",
      "Batch size : 151 , Loss value : 0.02430076\n",
      "Batch size : 47 , Loss value : 0.029117685\n",
      "Batch size : 114 , Loss value : 0.01694035\n",
      "Batch size : 330 , Loss value : 0.023743575\n",
      "Batch size : 89 , Loss value : 0.019494578\n",
      "Batch size : 167 , Loss value : 0.022164222\n",
      "Batch size : 112 , Loss value : 0.018086469\n",
      "Batch size : 130 , Loss value : 0.024009421\n",
      "Batch size : 37 , Loss value : 0.018956667\n",
      "Batch size : 159 , Loss value : 0.019169897\n",
      "Batch size : 8 , Loss value : 0.014451243\n",
      "Batch size : 63 , Loss value : 0.013783936\n",
      "Batch size : 272 , Loss value : 0.014549714\n",
      "Batch size : 135 , Loss value : 0.01382768\n",
      "Batch size : 39 , Loss value : 0.01785065\n",
      "Batch size : 81 , Loss value : 0.015200374\n",
      "Batch size : 117 , Loss value : 0.021684472\n",
      "Batch size : 105 , Loss value : 0.013422693\n",
      "Batch size : 101 , Loss value : 0.019449672\n",
      "Batch size : 65 , Loss value : 0.018978585\n",
      "Batch size : 9 , Loss value : 0.02842919\n",
      "Batch size : 59 , Loss value : 0.020459102\n",
      "Batch size : 81 , Loss value : 0.026867546\n",
      "Batch size : 74 , Loss value : 0.026107673\n",
      "Batch size : 57 , Loss value : 0.017159464\n",
      "Batch size : 93 , Loss value : 0.01745096\n",
      "Batch size : 33 , Loss value : 0.012598092\n",
      "Batch size : 65 , Loss value : 0.013654333\n",
      "Batch size : 47 , Loss value : 0.01230504\n",
      "Batch size : 136 , Loss value : 0.019933507\n",
      "Batch size : 53 , Loss value : 0.014780045\n",
      "Batch size : 172 , Loss value : 0.017469188\n",
      "Batch size : 67 , Loss value : 0.018297609\n",
      "Batch size : 230 , Loss value : 0.019296328\n",
      "Batch size : 100 , Loss value : 0.01253894\n",
      "Batch size : 242 , Loss value : 0.010760463\n",
      "Batch size : 56 , Loss value : 0.026351158\n",
      "Batch size : 135 , Loss value : 0.013009281\n",
      "Batch size : 257 , Loss value : 0.019450929\n",
      "Batch size : 48 , Loss value : 0.009066033\n",
      "Batch size : 52 , Loss value : 0.014425536\n",
      "Batch size : 104 , Loss value : 0.014346593\n",
      "Batch size : 94 , Loss value : 0.015264487\n",
      "Batch size : 6 , Loss value : 0.006985393\n",
      "Batch size : 35 , Loss value : 0.00709261\n",
      "Batch size : 77 , Loss value : 0.015050173\n",
      "Batch size : 152 , Loss value : 0.013212195\n",
      "Batch size : 162 , Loss value : 0.014834792\n",
      "Batch size : 255 , Loss value : 0.014099802\n",
      "Batch size : 80 , Loss value : 0.015015525\n",
      "Batch size : 110 , Loss value : 0.014308685\n",
      "Batch size : 22 , Loss value : 0.014679516\n",
      "Batch size : 10 , Loss value : 0.0042912983\n",
      "Batch size : 141 , Loss value : 0.01163331\n",
      "Batch size : 52 , Loss value : 0.011739206\n",
      "Batch size : 141 , Loss value : 0.012153118\n",
      "Batch size : 111 , Loss value : 0.012507229\n",
      "Batch size : 250 , Loss value : 0.012817396\n",
      "Batch size : 57 , Loss value : 0.00831741\n",
      "Batch size : 99 , Loss value : 0.009218292\n",
      "Batch size : 118 , Loss value : 0.011560818\n",
      "Batch size : 169 , Loss value : 0.011095294\n",
      "Batch size : 41 , Loss value : 0.010211287\n",
      "Batch size : 6 , Loss value : 0.009515707\n",
      "Batch size : 48 , Loss value : 0.010783627\n",
      "Batch size : 33 , Loss value : 0.011092227\n",
      "Batch size : 17 , Loss value : 0.00993842\n",
      "Batch size : 85 , Loss value : 0.012792344\n",
      "Batch size : 79 , Loss value : 0.010716139\n",
      "Batch size : 94 , Loss value : 0.00974187\n",
      "Batch size : 6 , Loss value : 0.013677787\n",
      "Batch size : 58 , Loss value : 0.0064575155\n",
      "Batch size : 125 , Loss value : 0.010199496\n",
      "Batch size : 64 , Loss value : 0.009287277\n",
      "Batch size : 59 , Loss value : 0.0063679344\n",
      "Batch size : 27 , Loss value : 0.0043723094\n",
      "Batch size : 158 , Loss value : 0.010478925\n",
      "Batch size : 158 , Loss value : 0.01139129\n",
      "Batch size : 44 , Loss value : 0.011446453\n",
      "Batch size : 268 , Loss value : 0.009333409\n",
      "Batch size : 148 , Loss value : 0.011785901\n",
      "Batch size : 68 , Loss value : 0.013362844\n",
      "Batch size : 37 , Loss value : 0.017818294\n",
      "Batch size : 19 , Loss value : 0.010168772\n",
      "Batch size : 203 , Loss value : 0.010542126\n",
      "Batch size : 102 , Loss value : 0.017379336\n",
      "Batch size : 54 , Loss value : 0.008199278\n",
      "Batch size : 112 , Loss value : 0.008404101\n",
      "Batch size : 137 , Loss value : 0.011166648\n",
      "Batch size : 22 , Loss value : 0.007553984\n",
      "Batch size : 11 , Loss value : 0.007939595\n",
      "Batch size : 137 , Loss value : 0.008134935\n",
      "Batch size : 16 , Loss value : 0.007864559\n",
      "Batch size : 45 , Loss value : 0.0055634454\n",
      "Batch size : 35 , Loss value : 0.00836844\n",
      "Batch size : 48 , Loss value : 0.0066969623\n",
      "Batch size : 209 , Loss value : 0.012426495\n",
      "Batch size : 22 , Loss value : 0.0076566217\n",
      "Batch size : 129 , Loss value : 0.011361168\n",
      "Batch size : 82 , Loss value : 0.008349589\n",
      "Batch size : 2 , Loss value : 0.006661171\n",
      "Batch size : 8 , Loss value : 0.0026780134\n",
      "Batch size : 163 , Loss value : 0.008326978\n",
      "Batch size : 134 , Loss value : 0.007638472\n",
      "Batch size : 139 , Loss value : 0.011536268\n",
      "Batch size : 198 , Loss value : 0.009970214\n",
      "Batch size : 141 , Loss value : 0.008259005\n",
      "Batch size : 222 , Loss value : 0.009460818\n",
      "Batch size : 19 , Loss value : 0.009840948\n",
      "Batch size : 29 , Loss value : 0.006311942\n",
      "Batch size : 55 , Loss value : 0.005262326\n",
      "Batch size : 63 , Loss value : 0.0066849357\n",
      "Batch size : 80 , Loss value : 0.011222761\n",
      "Batch size : 69 , Loss value : 0.008861346\n",
      "Batch size : 43 , Loss value : 0.011691128\n",
      "Batch size : 161 , Loss value : 0.009218632\n",
      "Batch size : 189 , Loss value : 0.011223917\n",
      "Batch size : 229 , Loss value : 0.012959023\n",
      "Batch size : 99 , Loss value : 0.008657208\n",
      "Batch size : 34 , Loss value : 0.0057052444\n",
      "Batch size : 79 , Loss value : 0.008948588\n",
      "Batch size : 107 , Loss value : 0.0072059995\n",
      "Batch size : 71 , Loss value : 0.008732584\n",
      "Batch size : 421 , Loss value : 0.011820641\n",
      "Batch size : 117 , Loss value : 0.009259708\n",
      "Batch size : 60 , Loss value : 0.010275482\n",
      "Batch size : 174 , Loss value : 0.007309664\n",
      "Batch size : 24 , Loss value : 0.0074375994\n",
      "Batch size : 173 , Loss value : 0.008905158\n",
      "Batch size : 63 , Loss value : 0.007213434\n",
      "Batch size : 69 , Loss value : 0.0052819587\n",
      "Batch size : 4 , Loss value : 0.0020887954\n",
      "Batch size : 42 , Loss value : 0.0062623527\n",
      "Batch size : 12 , Loss value : 0.007392734\n",
      "Batch size : 96 , Loss value : 0.0063797776\n",
      "Batch size : 35 , Loss value : 0.0059908894\n",
      "Batch size : 123 , Loss value : 0.0072590294\n",
      "Batch size : 103 , Loss value : 0.007775516\n",
      "Batch size : 92 , Loss value : 0.008638245\n",
      "Batch size : 167 , Loss value : 0.006906345\n",
      "Batch size : 125 , Loss value : 0.010965686\n",
      "Batch size : 73 , Loss value : 0.006334136\n",
      "Batch size : 26 , Loss value : 0.0063102525\n",
      "Batch size : 229 , Loss value : 0.0068938504\n",
      "Batch size : 13 , Loss value : 0.0039984575\n",
      "Batch size : 174 , Loss value : 0.0068060686\n",
      "Batch size : 205 , Loss value : 0.0064865956\n",
      "Batch size : 50 , Loss value : 0.005397281\n",
      "Batch size : 12 , Loss value : 0.00672967\n",
      "Batch size : 92 , Loss value : 0.008087253\n",
      "Batch size : 64 , Loss value : 0.00940092\n",
      "Batch size : 146 , Loss value : 0.0053100535\n",
      "Batch size : 30 , Loss value : 0.008145968\n",
      "Batch size : 14 , Loss value : 0.004298695\n",
      "Batch size : 78 , Loss value : 0.0048138667\n",
      "Batch size : 188 , Loss value : 0.013418276\n",
      "Batch size : 211 , Loss value : 0.007641031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 150 , Loss value : 0.007882669\n",
      "Batch size : 42 , Loss value : 0.0074720853\n",
      "Batch size : 12 , Loss value : 0.004085541\n",
      "Batch size : 39 , Loss value : 0.008045527\n",
      "Batch size : 28 , Loss value : 0.008440463\n",
      "Batch size : 35 , Loss value : 0.005950009\n",
      "Batch size : 41 , Loss value : 0.007859976\n",
      "Batch size : 9 , Loss value : 0.009427552\n",
      "Batch size : 120 , Loss value : 0.006612892\n",
      "Batch size : 13 , Loss value : 0.005494655\n",
      "Batch size : 140 , Loss value : 0.005170847\n",
      "Batch size : 71 , Loss value : 0.005475818\n",
      "Batch size : 103 , Loss value : 0.00717103\n",
      "Batch size : 98 , Loss value : 0.007844902\n",
      "Batch size : 15 , Loss value : 0.006512259\n",
      "Batch size : 180 , Loss value : 0.0070383376\n",
      "Batch size : 130 , Loss value : 0.007966846\n",
      "Batch size : 279 , Loss value : 0.006555822\n",
      "Batch size : 14 , Loss value : 0.0047020954\n",
      "Batch size : 124 , Loss value : 0.0071444516\n",
      "Batch size : 35 , Loss value : 0.0067542973\n",
      "Batch size : 45 , Loss value : 0.0045880484\n",
      "Batch size : 70 , Loss value : 0.0060862745\n",
      "Batch size : 81 , Loss value : 0.005301781\n",
      "Batch size : 18 , Loss value : 0.0061818543\n",
      "Batch size : 34 , Loss value : 0.004819443\n",
      "Batch size : 87 , Loss value : 0.0043273317\n",
      "Batch size : 196 , Loss value : 0.0056733144\n",
      "Batch size : 82 , Loss value : 0.0041084737\n",
      "Batch size : 114 , Loss value : 0.0049631395\n",
      "Batch size : 12 , Loss value : 0.005720053\n",
      "Batch size : 175 , Loss value : 0.0041385093\n",
      "Batch size : 133 , Loss value : 0.0048579006\n",
      "Batch size : 102 , Loss value : 0.005689744\n",
      "Batch size : 41 , Loss value : 0.0036651187\n",
      "Batch size : 47 , Loss value : 0.0063655535\n",
      "Batch size : 89 , Loss value : 0.0036052733\n",
      "Batch size : 183 , Loss value : 0.007516285\n",
      "Batch size : 14 , Loss value : 0.002990548\n",
      "Batch size : 35 , Loss value : 0.0037376496\n",
      "Batch size : 4 , Loss value : 0.007502856\n",
      "Batch size : 43 , Loss value : 0.0054035666\n",
      "Batch size : 67 , Loss value : 0.005713892\n",
      "Batch size : 10 , Loss value : 0.0033533364\n",
      "Batch size : 68 , Loss value : 0.00640744\n",
      "Batch size : 210 , Loss value : 0.0053667245\n",
      "Batch size : 142 , Loss value : 0.005032031\n",
      "Batch size : 120 , Loss value : 0.0039475006\n",
      "Batch size : 61 , Loss value : 0.0037802262\n",
      "Batch size : 4 , Loss value : 0.0032584192\n",
      "Batch size : 20 , Loss value : 0.0077855065\n",
      "Batch size : 72 , Loss value : 0.004204494\n",
      "Batch size : 27 , Loss value : 0.005629468\n",
      "Batch size : 53 , Loss value : 0.0054692826\n",
      "Batch size : 56 , Loss value : 0.004338653\n",
      "Batch size : 79 , Loss value : 0.004707028\n",
      "Batch size : 17 , Loss value : 0.0052666464\n",
      "Batch size : 91 , Loss value : 0.0066043846\n",
      "Batch size : 86 , Loss value : 0.0053899437\n",
      "Batch size : 71 , Loss value : 0.004631483\n",
      "Batch size : 10 , Loss value : 0.0070576696\n",
      "Batch size : 62 , Loss value : 0.0052024564\n",
      "Batch size : 10 , Loss value : 0.0064140307\n",
      "Batch size : 90 , Loss value : 0.0055837934\n",
      "Batch size : 119 , Loss value : 0.0046394267\n",
      "Batch size : 44 , Loss value : 0.0045268964\n",
      "Batch size : 173 , Loss value : 0.005805135\n",
      "Batch size : 78 , Loss value : 0.0047410033\n",
      "Batch size : 7 , Loss value : 0.003998713\n",
      "Batch size : 180 , Loss value : 0.005153165\n",
      "Batch size : 41 , Loss value : 0.0056117675\n",
      "Batch size : 21 , Loss value : 0.005320939\n",
      "Batch size : 7 , Loss value : 0.0057689524\n",
      "Batch size : 33 , Loss value : 0.0036544746\n",
      "Batch size : 69 , Loss value : 0.004160653\n",
      "Batch size : 36 , Loss value : 0.005804486\n",
      "Batch size : 203 , Loss value : 0.006710943\n",
      "Batch size : 17 , Loss value : 0.0069987136\n",
      "Batch size : 20 , Loss value : 0.0036359057\n",
      "Batch size : 93 , Loss value : 0.005364461\n",
      "Batch size : 39 , Loss value : 0.004507306\n",
      "Batch size : 143 , Loss value : 0.005739378\n",
      "Batch size : 6 , Loss value : 0.0051326603\n",
      "Batch size : 147 , Loss value : 0.0050740414\n",
      "Batch size : 52 , Loss value : 0.003631992\n",
      "Batch size : 415 , Loss value : 0.004105388\n",
      "Batch size : 113 , Loss value : 0.004643807\n",
      "Batch size : 119 , Loss value : 0.004780114\n",
      "Batch size : 99 , Loss value : 0.00632409\n",
      "Batch size : 259 , Loss value : 0.0040580416\n",
      "Batch size : 131 , Loss value : 0.0038347545\n",
      "Batch size : 38 , Loss value : 0.0067769876\n",
      "Batch size : 63 , Loss value : 0.0056476053\n",
      "Batch size : 14 , Loss value : 0.0046963915\n",
      "Batch size : 20 , Loss value : 0.0040208753\n",
      "Batch size : 96 , Loss value : 0.0052651498\n",
      "Batch size : 178 , Loss value : 0.0049453694\n",
      "Batch size : 77 , Loss value : 0.0039142678\n",
      "Batch size : 306 , Loss value : 0.004447589\n",
      "Batch size : 66 , Loss value : 0.0030617225\n",
      "Batch size : 263 , Loss value : 0.002620281\n",
      "Batch size : 129 , Loss value : 0.003729431\n",
      "Batch size : 74 , Loss value : 0.0034851513\n",
      "Batch size : 95 , Loss value : 0.004304605\n",
      "Batch size : 129 , Loss value : 0.0034739934\n",
      "Batch size : 72 , Loss value : 0.0045779613\n",
      "Batch size : 77 , Loss value : 0.0037856463\n",
      "Batch size : 84 , Loss value : 0.004072115\n",
      "Batch size : 22 , Loss value : 0.0027725494\n",
      "Batch size : 37 , Loss value : 0.003142832\n",
      "Batch size : 117 , Loss value : 0.0043124827\n",
      "Batch size : 258 , Loss value : 0.0039775963\n",
      "Batch size : 80 , Loss value : 0.0037474837\n",
      "Batch size : 89 , Loss value : 0.0032864795\n",
      "Batch size : 47 , Loss value : 0.004002596\n",
      "Batch size : 16 , Loss value : 0.0024525665\n",
      "Batch size : 41 , Loss value : 0.0036529745\n",
      "Batch size : 87 , Loss value : 0.0042637135\n",
      "Batch size : 137 , Loss value : 0.0037091775\n",
      "Batch size : 32 , Loss value : 0.0038890424\n",
      "(6277, 200, 20)\n",
      "(6277, 518)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pnaddaf/anaconda3/envs/env/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6277, 200, 20)\n",
      "(6277, 518)\n",
      "\tTrain Loss for this epoch : 0.011102137\n",
      "\tTrain Accuracy for this epoch: 0.6083898438732062\n",
      "\tValidation Accuracy for this epoch: 0.584380389258438\n",
      "Epoch  1 (0, 20, 0.001, 100, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pnaddaf/anaconda3/envs/env/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 248 , Loss value : 0.00480663\n",
      "Batch size : 23 , Loss value : 0.001230774\n",
      "Batch size : 39 , Loss value : 0.0025493656\n",
      "Batch size : 69 , Loss value : 0.0027631675\n",
      "Batch size : 174 , Loss value : 0.0032662365\n",
      "Batch size : 127 , Loss value : 0.0030007034\n",
      "Batch size : 49 , Loss value : 0.002812446\n",
      "Batch size : 115 , Loss value : 0.0023518866\n",
      "Batch size : 230 , Loss value : 0.0030538745\n",
      "Batch size : 61 , Loss value : 0.0026824756\n",
      "Batch size : 45 , Loss value : 0.004080973\n",
      "Batch size : 9 , Loss value : 0.0025069346\n",
      "Batch size : 24 , Loss value : 0.001728483\n",
      "Batch size : 91 , Loss value : 0.0023330352\n",
      "Batch size : 135 , Loss value : 0.0030946839\n",
      "Batch size : 123 , Loss value : 0.0024066255\n",
      "Batch size : 104 , Loss value : 0.004372474\n",
      "Batch size : 89 , Loss value : 0.0022356822\n",
      "Batch size : 10 , Loss value : 0.0011249947\n",
      "Batch size : 112 , Loss value : 0.00348364\n",
      "Batch size : 103 , Loss value : 0.002571547\n",
      "Batch size : 171 , Loss value : 0.0031254003\n",
      "Batch size : 21 , Loss value : 0.00040796516\n",
      "Batch size : 163 , Loss value : 0.0019217784\n",
      "Batch size : 233 , Loss value : 0.00097618584\n",
      "Batch size : 226 , Loss value : 0.00049271266\n",
      "Batch size : 68 , Loss value : 0.00022754156\n",
      "Batch size : 81 , Loss value : 0.0\n",
      "Batch size : 238 , Loss value : 3.769655e-05\n",
      "Batch size : 96 , Loss value : 0.0012253624\n",
      "Batch size : 35 , Loss value : 7.275687e-05\n",
      "Batch size : 79 , Loss value : 0.0\n",
      "Batch size : 262 , Loss value : 0.0016784568\n",
      "Batch size : 107 , Loss value : 0.0015572108\n",
      "Batch size : 2 , Loss value : 0.00028573634\n",
      "Batch size : 192 , Loss value : 0.0009054425\n",
      "Batch size : 10 , Loss value : 0.0009622839\n",
      "Batch size : 28 , Loss value : 5.9673515e-05\n",
      "Batch size : 121 , Loss value : 0.0001443717\n",
      "Batch size : 5 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.004122825\n",
      "Batch size : 254 , Loss value : 0.00097543414\n",
      "Batch size : 287 , Loss value : 0.00058014394\n",
      "Batch size : 194 , Loss value : 0.0009797704\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 14 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 13 , Loss value : 0.00095932814\n",
      "Batch size : 96 , Loss value : 0.00042586416\n",
      "Batch size : 70 , Loss value : 0.0009180219\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 83 , Loss value : 0.0\n",
      "Batch size : 17 , Loss value : 0.0\n",
      "Batch size : 199 , Loss value : 0.00028191463\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 352 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 132 , Loss value : 0.0008924559\n",
      "Batch size : 241 , Loss value : 0.0013076259\n",
      "Batch size : 29 , Loss value : 0.0\n",
      "Batch size : 97 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.00027951796\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 59 , Loss value : 0.0\n",
      "Batch size : 158 , Loss value : 0.0\n",
      "Batch size : 110 , Loss value : 0.0\n",
      "Batch size : 161 , Loss value : 0.0\n",
      "Batch size : 137 , Loss value : 0.0\n",
      "Batch size : 253 , Loss value : 0.0\n",
      "Batch size : 70 , Loss value : 0.0\n",
      "Batch size : 218 , Loss value : 0.0\n",
      "Batch size : 160 , Loss value : 0.0005373543\n",
      "Batch size : 229 , Loss value : 0.0\n",
      "Batch size : 46 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 92 , Loss value : 0.0\n",
      "Batch size : 88 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 90 , Loss value : 0.0\n",
      "Batch size : 110 , Loss value : 0.0\n",
      "Batch size : 33 , Loss value : 0.0\n",
      "Batch size : 114 , Loss value : 0.0\n",
      "Batch size : 314 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 41 , Loss value : 0.0\n",
      "Batch size : 78 , Loss value : 0.00046639747\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 218 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 16 , Loss value : 0.0\n",
      "Batch size : 902 , Loss value : 0.0\n",
      "Batch size : 96 , Loss value : 0.0\n",
      "Batch size : 119 , Loss value : 0.0\n",
      "Batch size : 113 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 33 , Loss value : 0.0002634389\n",
      "Batch size : 41 , Loss value : 0.0\n",
      "Batch size : 98 , Loss value : 0.0\n",
      "Batch size : 113 , Loss value : 0.00045066173\n",
      "Batch size : 204 , Loss value : 0.0\n",
      "Batch size : 117 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 117 , Loss value : 0.0\n",
      "Batch size : 128 , Loss value : 2.4180508e-05\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 5 , Loss value : 0.0\n",
      "Batch size : 136 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 76 , Loss value : 0.0\n",
      "Batch size : 17 , Loss value : 0.0\n",
      "Batch size : 103 , Loss value : 0.0\n",
      "Batch size : 86 , Loss value : 0.0\n",
      "Batch size : 73 , Loss value : 0.0\n",
      "Batch size : 104 , Loss value : 0.0\n",
      "Batch size : 19 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 116 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 132 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 59 , Loss value : 0.0\n",
      "Batch size : 140 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 204 , Loss value : 0.0\n",
      "Batch size : 4 , Loss value : 0.0\n",
      "Batch size : 206 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 163 , Loss value : 0.0\n",
      "Batch size : 72 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 37 , Loss value : 0.0\n",
      "Batch size : 81 , Loss value : 0.0\n",
      "Batch size : 207 , Loss value : 0.0\n",
      "Batch size : 79 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 122 , Loss value : 0.0\n",
      "Batch size : 196 , Loss value : 0.0\n",
      "Batch size : 138 , Loss value : 0.0\n",
      "Batch size : 161 , Loss value : 0.0\n",
      "Batch size : 251 , Loss value : 0.0\n",
      "Batch size : 143 , Loss value : 0.0\n",
      "Batch size : 101 , Loss value : 0.0\n",
      "Batch size : 73 , Loss value : 0.0\n",
      "Batch size : 150 , Loss value : 0.0\n",
      "Batch size : 113 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 48 , Loss value : 0.0\n",
      "Batch size : 103 , Loss value : 0.0\n",
      "Batch size : 265 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 84 , Loss value : 0.001534617\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 9.469219e-05\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 137 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 102 , Loss value : 0.0\n",
      "Batch size : 87 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 166 , Loss value : 0.0\n",
      "Batch size : 46 , Loss value : 0.0\n",
      "Batch size : 96 , Loss value : 0.0\n",
      "Batch size : 117 , Loss value : 0.0\n",
      "Batch size : 78 , Loss value : 0.0\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.00029687714\n",
      "Batch size : 177 , Loss value : 0.0\n",
      "Batch size : 77 , Loss value : 0.0\n",
      "Batch size : 85 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 199 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 98 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 35 , Loss value : 0.0\n",
      "Batch size : 12 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 13 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 14 , Loss value : 0.000444172\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 85 , Loss value : 0.0\n",
      "Batch size : 469 , Loss value : 0.0\n",
      "Batch size : 41 , Loss value : 0.0\n",
      "Batch size : 333 , Loss value : 0.0\n",
      "Batch size : 100 , Loss value : 0.0\n",
      "Batch size : 35 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 135 , Loss value : 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 79 , Loss value : 0.0\n",
      "Batch size : 16 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 16 , Loss value : 0.0\n",
      "Batch size : 17 , Loss value : 0.0\n",
      "Batch size : 377 , Loss value : 0.0\n",
      "Batch size : 141 , Loss value : 0.0\n",
      "Batch size : 29 , Loss value : 0.0\n",
      "Batch size : 33 , Loss value : 0.0\n",
      "Batch size : 126 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 69 , Loss value : 0.00043442828\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 60 , Loss value : 0.0\n",
      "Batch size : 84 , Loss value : 0.0\n",
      "Batch size : 134 , Loss value : 0.0\n",
      "Batch size : 178 , Loss value : 0.0\n",
      "Batch size : 78 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 305 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 131 , Loss value : 0.00029111104\n",
      "Batch size : 170 , Loss value : 0.0\n",
      "Batch size : 78 , Loss value : 0.0\n",
      "Batch size : 43 , Loss value : 0.0\n",
      "Batch size : 141 , Loss value : 0.00044469885\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 132 , Loss value : 0.0\n",
      "Batch size : 260 , Loss value : 3.163389e-05\n",
      "Batch size : 33 , Loss value : 9.1759985e-06\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 250 , Loss value : 0.0\n",
      "Batch size : 165 , Loss value : 0.0\n",
      "Batch size : 168 , Loss value : 0.0\n",
      "Batch size : 40 , Loss value : 0.0\n",
      "Batch size : 163 , Loss value : 0.00068924605\n",
      "Batch size : 516 , Loss value : 0.0\n",
      "Batch size : 79 , Loss value : 0.0\n",
      "Batch size : 82 , Loss value : 0.00028000405\n",
      "Batch size : 224 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 261 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.00046977718\n",
      "Batch size : 116 , Loss value : 0.0\n",
      "Batch size : 147 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 27 , Loss value : 0.0\n",
      "Batch size : 88 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 5 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 92 , Loss value : 0.0\n",
      "Batch size : 60 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 85 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 233 , Loss value : 0.0\n",
      "Batch size : 133 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 17 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 230 , Loss value : 0.0\n",
      "Batch size : 177 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 69 , Loss value : 0.0\n",
      "Batch size : 19 , Loss value : 0.0\n",
      "Batch size : 242 , Loss value : 0.0\n",
      "Batch size : 69 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 77 , Loss value : 0.0\n",
      "Batch size : 68 , Loss value : 0.0\n",
      "Batch size : 164 , Loss value : 0.0\n",
      "Batch size : 37 , Loss value : 0.00019504646\n",
      "Batch size : 52 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 240 , Loss value : 0.0\n",
      "Batch size : 55 , Loss value : 0.0\n",
      "Batch size : 91 , Loss value : 0.0\n",
      "(6277, 200, 20)\n",
      "(6277, 518)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pnaddaf/anaconda3/envs/env/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6277, 200, 20)\n",
      "(6277, 518)\n",
      "\tTrain Loss for this epoch : 0.00029520268\n",
      "\tTrain Accuracy for this epoch: 0.5676853252647504\n",
      "\tValidation Accuracy for this epoch: 0.6293611236973267\n",
      "Epoch  2 (0, 20, 0.001, 100, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 111 , Loss value : 0.0\n",
      "Batch size : 130 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 231 , Loss value : 0.0\n",
      "Batch size : 181 , Loss value : 0.0\n",
      "Batch size : 45 , Loss value : 0.0\n",
      "Batch size : 195 , Loss value : 0.0\n",
      "Batch size : 85 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 21 , Loss value : 0.0\n",
      "Batch size : 313 , Loss value : 0.0\n",
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 58 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.0\n",
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 45 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 95 , Loss value : 0.0\n",
      "Batch size : 87 , Loss value : 0.0\n",
      "Batch size : 80 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 13 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 106 , Loss value : 0.0\n",
      "Batch size : 12 , Loss value : 0.0\n",
      "Batch size : 144 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 107 , Loss value : 0.0\n",
      "Batch size : 40 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 41 , Loss value : 0.0\n",
      "Batch size : 251 , Loss value : 0.0\n",
      "Batch size : 214 , Loss value : 0.0\n",
      "Batch size : 136 , Loss value : 0.0\n",
      "Batch size : 85 , Loss value : 0.0\n",
      "Batch size : 171 , Loss value : 0.0\n",
      "Batch size : 31 , Loss value : 0.0\n",
      "Batch size : 240 , Loss value : 0.00033020639\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 86 , Loss value : 0.0\n",
      "Batch size : 43 , Loss value : 0.0\n",
      "Batch size : 92 , Loss value : 0.0\n",
      "Batch size : 2 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 184 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 16 , Loss value : 0.0\n",
      "Batch size : 37 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 161 , Loss value : 0.0004963263\n",
      "Batch size : 118 , Loss value : 0.0\n",
      "Batch size : 117 , Loss value : 0.0\n",
      "Batch size : 114 , Loss value : 0.0\n",
      "Batch size : 180 , Loss value : 0.0\n",
      "Batch size : 1 , Loss value : 0.0\n",
      "Batch size : 136 , Loss value : 0.0\n",
      "Batch size : 256 , Loss value : 0.0\n",
      "Batch size : 104 , Loss value : 0.0\n",
      "Batch size : 141 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 80 , Loss value : 0.00025411262\n",
      "Batch size : 184 , Loss value : 0.0\n",
      "Batch size : 142 , Loss value : 0.0\n",
      "Batch size : 82 , Loss value : 0.0\n",
      "Batch size : 46 , Loss value : 0.0\n",
      "Batch size : 179 , Loss value : 0.0\n",
      "Batch size : 81 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 59 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.00020508961\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 161 , Loss value : 0.0\n",
      "Batch size : 197 , Loss value : 0.0\n",
      "Batch size : 76 , Loss value : 0.00026813336\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 81 , Loss value : 0.0\n",
      "Batch size : 362 , Loss value : 0.0\n",
      "Batch size : 307 , Loss value : 0.0002092304\n",
      "Batch size : 157 , Loss value : 0.00012039244\n",
      "Batch size : 92 , Loss value : 0.00065065693\n",
      "Batch size : 283 , Loss value : 1.4091927e-05\n",
      "Batch size : 239 , Loss value : 0.0\n",
      "Batch size : 107 , Loss value : 0.0\n",
      "Batch size : 164 , Loss value : 0.0\n",
      "Batch size : 113 , Loss value : 0.0\n",
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 310 , Loss value : 0.00042396225\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 178 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 129 , Loss value : 0.0\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 155 , Loss value : 0.0\n",
      "Batch size : 104 , Loss value : 0.00051870133\n",
      "Batch size : 64 , Loss value : 0.0\n",
      "Batch size : 622 , Loss value : 1.914251e-05\n",
      "Batch size : 84 , Loss value : 0.0\n",
      "Batch size : 50 , Loss value : 0.0\n",
      "Batch size : 34 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 463 , Loss value : 0.0\n",
      "Batch size : 183 , Loss value : 0.0\n",
      "Batch size : 100 , Loss value : 0.0\n",
      "Batch size : 84 , Loss value : 0.0\n",
      "Batch size : 34 , Loss value : 0.0\n",
      "Batch size : 214 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 7 , Loss value : 0.0\n",
      "Batch size : 41 , Loss value : 0.0\n",
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 107 , Loss value : 0.0\n",
      "Batch size : 95 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 34 , Loss value : 0.0\n",
      "Batch size : 88 , Loss value : 0.0\n",
      "Batch size : 80 , Loss value : 0.0\n",
      "Batch size : 78 , Loss value : 0.0\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 162 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 45 , Loss value : 0.000719111\n",
      "Batch size : 92 , Loss value : 0.0\n",
      "Batch size : 136 , Loss value : 0.0\n",
      "Batch size : 12 , Loss value : 0.0\n",
      "Batch size : 94 , Loss value : 0.0\n",
      "Batch size : 210 , Loss value : 0.0\n",
      "Batch size : 70 , Loss value : 0.0\n",
      "Batch size : 121 , Loss value : 0.0\n",
      "Batch size : 80 , Loss value : 0.0\n",
      "Batch size : 58 , Loss value : 8.5678854e-05\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 87 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 86 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.00056857854\n",
      "Batch size : 136 , Loss value : 0.0\n",
      "Batch size : 33 , Loss value : 0.0\n",
      "Batch size : 69 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 83 , Loss value : 0.00016292589\n",
      "Batch size : 204 , Loss value : 0.0\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 84 , Loss value : 0.0\n",
      "Batch size : 131 , Loss value : 0.0\n",
      "Batch size : 82 , Loss value : 0.00013535943\n",
      "Batch size : 92 , Loss value : 0.0\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 55 , Loss value : 0.0\n",
      "Batch size : 97 , Loss value : 0.0\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 129 , Loss value : 0.0\n",
      "Batch size : 134 , Loss value : 0.0\n",
      "Batch size : 176 , Loss value : 0.0\n",
      "Batch size : 71 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 77 , Loss value : 0.0\n",
      "Batch size : 69 , Loss value : 0.0\n",
      "Batch size : 74 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 152 , Loss value : 0.0\n",
      "Batch size : 278 , Loss value : 0.0005583916\n",
      "Batch size : 182 , Loss value : 0.00034158266\n",
      "Batch size : 104 , Loss value : 0.0\n",
      "Batch size : 4 , Loss value : 0.0\n",
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 19 , Loss value : 0.0\n",
      "Batch size : 192 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 173 , Loss value : 0.0\n",
      "Batch size : 86 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 6.0968105e-05\n",
      "Batch size : 105 , Loss value : 0.0\n",
      "Batch size : 17 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 76 , Loss value : 0.0\n",
      "Batch size : 74 , Loss value : 0.0\n",
      "Batch size : 122 , Loss value : 0.0\n",
      "Batch size : 178 , Loss value : 0.0\n",
      "Batch size : 1 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 135 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 50 , Loss value : 0.0\n",
      "Batch size : 180 , Loss value : 0.0\n",
      "Batch size : 150 , Loss value : 0.0\n",
      "Batch size : 171 , Loss value : 0.0\n",
      "Batch size : 21 , Loss value : 0.0\n",
      "Batch size : 74 , Loss value : 0.0\n",
      "Batch size : 27 , Loss value : 0.0\n",
      "Batch size : 113 , Loss value : 0.0\n",
      "Batch size : 141 , Loss value : 7.790359e-05\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.0\n",
      "Batch size : 59 , Loss value : 0.0\n",
      "Batch size : 132 , Loss value : 0.0\n",
      "Batch size : 154 , Loss value : 0.0\n",
      "Batch size : 192 , Loss value : 0.0\n",
      "Batch size : 104 , Loss value : 0.0\n",
      "Batch size : 400 , Loss value : 0.0\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 88 , Loss value : 0.0\n",
      "Batch size : 105 , Loss value : 0.0\n",
      "Batch size : 2 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 148 , Loss value : 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 235 , Loss value : 0.0\n",
      "Batch size : 133 , Loss value : 0.0\n",
      "Batch size : 100 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 15 , Loss value : 0.0\n",
      "Batch size : 131 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 103 , Loss value : 0.0\n",
      "Batch size : 107 , Loss value : 0.0\n",
      "Batch size : 306 , Loss value : 0.0\n",
      "Batch size : 211 , Loss value : 0.0\n",
      "Batch size : 131 , Loss value : 0.0\n",
      "Batch size : 191 , Loss value : 0.0\n",
      "Batch size : 271 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 92 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 300 , Loss value : 0.0\n",
      "Batch size : 335 , Loss value : 0.00026512923\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 43 , Loss value : 0.0\n",
      "Batch size : 110 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 3 , Loss value : 0.0\n",
      "Batch size : 35 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 5 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 142 , Loss value : 0.0\n",
      "Batch size : 29 , Loss value : 0.0\n",
      "Batch size : 83 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 102 , Loss value : 0.0\n",
      "Batch size : 131 , Loss value : 0.0\n",
      "Batch size : 117 , Loss value : 0.0\n",
      "Batch size : 97 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 144 , Loss value : 0.0\n",
      "Batch size : 153 , Loss value : 0.0\n",
      "Batch size : 115 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 77 , Loss value : 0.0\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 227 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 31 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 279 , Loss value : 0.0\n",
      "Batch size : 40 , Loss value : 0.0\n",
      "Batch size : 195 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 191 , Loss value : 0.0\n",
      "Batch size : 116 , Loss value : 0.0\n",
      "Batch size : 45 , Loss value : 0.0\n",
      "Batch size : 93 , Loss value : 0.0\n",
      "Batch size : 254 , Loss value : 0.0\n",
      "Batch size : 104 , Loss value : 0.0\n",
      "Batch size : 5 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 69 , Loss value : 0.0\n",
      "Batch size : 52 , Loss value : 0.0\n",
      "Batch size : 139 , Loss value : 0.0\n",
      "Batch size : 74 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 377 , Loss value : 0.0\n",
      "Batch size : 95 , Loss value : 0.0\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 140 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "(6277, 200, 20)\n",
      "(6277, 518)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pnaddaf/anaconda3/envs/env/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6277, 200, 20)\n",
      "(6277, 518)\n",
      "\tTrain Loss for this epoch : 2.0854262e-05\n",
      "\tTrain Accuracy for this epoch: 0.653327088029509\n",
      "\tValidation Accuracy for this epoch: 0.5071380013596193\n",
      "Epoch  3 (0, 20, 0.001, 100, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pnaddaf/anaconda3/envs/env/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 111 , Loss value : 0.0\n",
      "Batch size : 118 , Loss value : 0.0\n",
      "Batch size : 93 , Loss value : 0.0\n",
      "Batch size : 155 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 191 , Loss value : 0.0\n",
      "Batch size : 93 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 173 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 76 , Loss value : 0.0\n",
      "Batch size : 65 , Loss value : 0.0\n",
      "Batch size : 196 , Loss value : 0.0\n",
      "Batch size : 269 , Loss value : 0.0\n",
      "Batch size : 3 , Loss value : 0.0\n",
      "Batch size : 121 , Loss value : 0.0\n",
      "Batch size : 21 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 307 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 95 , Loss value : 3.8087386e-05\n",
      "Batch size : 239 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 43 , Loss value : 0.0\n",
      "Batch size : 116 , Loss value : 0.0\n",
      "Batch size : 29 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 37 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 118 , Loss value : 0.0\n",
      "Batch size : 78 , Loss value : 0.0\n",
      "Batch size : 154 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0010884095\n",
      "Batch size : 93 , Loss value : 0.0\n",
      "Batch size : 183 , Loss value : 0.0\n",
      "Batch size : 154 , Loss value : 0.0\n",
      "Batch size : 41 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 168 , Loss value : 0.0\n",
      "Batch size : 151 , Loss value : 0.0\n",
      "Batch size : 96 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 64 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 150 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 79 , Loss value : 0.0\n",
      "Batch size : 212 , Loss value : 0.0\n",
      "Batch size : 158 , Loss value : 0.0\n",
      "Batch size : 45 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 17 , Loss value : 0.0\n",
      "Batch size : 114 , Loss value : 0.0\n",
      "Batch size : 68 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 4 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 71 , Loss value : 0.0\n",
      "Batch size : 98 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 87 , Loss value : 0.0\n",
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 46 , Loss value : 0.0\n",
      "Batch size : 151 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 164 , Loss value : 0.0\n",
      "Batch size : 27 , Loss value : 0.0\n",
      "Batch size : 73 , Loss value : 0.0\n",
      "Batch size : 225 , Loss value : 0.0\n",
      "Batch size : 128 , Loss value : 0.0\n",
      "Batch size : 15 , Loss value : 0.0\n",
      "Batch size : 149 , Loss value : 0.0\n",
      "Batch size : 48 , Loss value : 0.0\n",
      "Batch size : 34 , Loss value : 0.0\n",
      "Batch size : 122 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 95 , Loss value : 0.0\n",
      "Batch size : 147 , Loss value : 0.0\n",
      "Batch size : 80 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 43 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 318 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 34 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 83 , Loss value : 0.0\n",
      "Batch size : 174 , Loss value : 0.0\n",
      "Batch size : 281 , Loss value : 0.0\n",
      "Batch size : 200 , Loss value : 0.0\n",
      "Batch size : 171 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.00019518012\n",
      "Batch size : 52 , Loss value : 0.0\n",
      "Batch size : 230 , Loss value : 0.0\n",
      "Batch size : 130 , Loss value : 0.0\n",
      "Batch size : 35 , Loss value : 0.0\n",
      "Batch size : 163 , Loss value : 0.0\n",
      "Batch size : 74 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 90 , Loss value : 0.0\n",
      "Batch size : 76 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 12 , Loss value : 0.0\n",
      "Batch size : 216 , Loss value : 0.0\n",
      "Batch size : 29 , Loss value : 0.0\n",
      "Batch size : 318 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 176 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 229 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 85 , Loss value : 0.0\n",
      "Batch size : 48 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 135 , Loss value : 0.0\n",
      "Batch size : 113 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.0\n",
      "Batch size : 37 , Loss value : 0.0\n",
      "Batch size : 114 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 4 , Loss value : 0.0\n",
      "Batch size : 33 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 31 , Loss value : 0.0\n",
      "Batch size : 71 , Loss value : 0.0006750727\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 178 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 40 , Loss value : 0.0\n",
      "Batch size : 193 , Loss value : 0.0\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 128 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 93 , Loss value : 0.0\n",
      "Batch size : 91 , Loss value : 0.0\n",
      "Batch size : 101 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 125 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 43 , Loss value : 0.0\n",
      "Batch size : 164 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 235 , Loss value : 0.0\n",
      "Batch size : 93 , Loss value : 0.0\n",
      "Batch size : 34 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 175 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 60 , Loss value : 0.0\n",
      "Batch size : 33 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 104 , Loss value : 0.0\n",
      "Batch size : 171 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 16 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 13 , Loss value : 0.0\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 2 , Loss value : 0.0\n",
      "Batch size : 55 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 68 , Loss value : 0.0\n",
      "Batch size : 1 , Loss value : 0.0\n",
      "Batch size : 123 , Loss value : 0.0\n",
      "Batch size : 279 , Loss value : 0.0\n",
      "Batch size : 13 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 44 , Loss value : 0.0\n",
      "Batch size : 76 , Loss value : 0.0\n",
      "Batch size : 71 , Loss value : 0.0\n",
      "Batch size : 72 , Loss value : 0.0\n",
      "Batch size : 50 , Loss value : 0.0\n",
      "Batch size : 27 , Loss value : 0.0\n",
      "Batch size : 119 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 464 , Loss value : 0.0\n",
      "Batch size : 147 , Loss value : 0.0\n",
      "Batch size : 134 , Loss value : 0.0\n",
      "Batch size : 116 , Loss value : 0.0\n",
      "Batch size : 58 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.0\n",
      "Batch size : 79 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 29 , Loss value : 0.0\n",
      "Batch size : 121 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 59 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 69 , Loss value : 0.0\n",
      "Batch size : 117 , Loss value : 0.0\n",
      "Batch size : 35 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 4 , Loss value : 0.0\n",
      "Batch size : 16 , Loss value : 0.0\n",
      "Batch size : 13 , Loss value : 0.0\n",
      "Batch size : 295 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 80 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 120 , Loss value : 0.0\n",
      "Batch size : 39 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.00044139\n",
      "Batch size : 131 , Loss value : 0.0\n",
      "Batch size : 104 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 102 , Loss value : 0.0\n",
      "Batch size : 247 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 81 , Loss value : 0.0\n",
      "Batch size : 77 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 253 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.0\n",
      "Batch size : 64 , Loss value : 0.0\n",
      "Batch size : 461 , Loss value : 0.0\n",
      "Batch size : 107 , Loss value : 0.0\n",
      "Batch size : 64 , Loss value : 0.0\n",
      "Batch size : 102 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 105 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 40 , Loss value : 0.0\n",
      "Batch size : 59 , Loss value : 0.0\n",
      "Batch size : 73 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 98 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 53 , Loss value : 0.0\n",
      "Batch size : 120 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0006732028\n",
      "Batch size : 131 , Loss value : 0.0\n",
      "Batch size : 111 , Loss value : 0.0\n",
      "Batch size : 75 , Loss value : 0.0\n",
      "Batch size : 68 , Loss value : 0.0\n",
      "Batch size : 601 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 40 , Loss value : 0.0\n",
      "Batch size : 277 , Loss value : 0.00074945315\n",
      "Batch size : 45 , Loss value : 0.0\n",
      "Batch size : 267 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 4.0859454e-06\n",
      "Batch size : 72 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 373 , Loss value : 0.0\n",
      "Batch size : 94 , Loss value : 1.7977734e-05\n",
      "Batch size : 50 , Loss value : 0.0\n",
      "Batch size : 129 , Loss value : 0.0\n",
      "Batch size : 27 , Loss value : 0.0\n",
      "Batch size : 301 , Loss value : 0.0\n",
      "Batch size : 126 , Loss value : 0.0\n",
      "Batch size : 172 , Loss value : 0.0\n",
      "Batch size : 169 , Loss value : 0.0\n",
      "Batch size : 37 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 69 , Loss value : 0.0\n",
      "Batch size : 148 , Loss value : 0.0\n",
      "Batch size : 148 , Loss value : 0.0\n",
      "Batch size : 64 , Loss value : 0.0\n",
      "Batch size : 6 , Loss value : 0.0\n",
      "Batch size : 58 , Loss value : 0.0\n",
      "Batch size : 155 , Loss value : 4.361529e-05\n",
      "Batch size : 76 , Loss value : 0.0\n",
      "Batch size : 305 , Loss value : 0.0\n",
      "Batch size : 102 , Loss value : 0.0\n",
      "Batch size : 67 , Loss value : 0.0\n",
      "Batch size : 26 , Loss value : 0.0\n",
      "Batch size : 272 , Loss value : 0.0\n",
      "Batch size : 55 , Loss value : 0.0\n",
      "(6277, 200, 20)\n",
      "(6277, 518)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pnaddaf/anaconda3/envs/env/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6277, 200, 20)\n",
      "(6277, 518)\n",
      "\tTrain Loss for this epoch : 1.2544648e-05\n",
      "\tTrain Accuracy for this epoch: 0.6533360658137424\n",
      "\tValidation Accuracy for this epoch: 0.6293611236973267\n",
      "Epoch  4 (0, 20, 0.001, 100, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d4ac25cea452bb4a991c0f936cac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 211 , Loss value : 0.0\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 84 , Loss value : 0.0\n",
      "Batch size : 113 , Loss value : 0.0\n",
      "Batch size : 12 , Loss value : 0.0\n",
      "Batch size : 2 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0\n",
      "Batch size : 114 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 42 , Loss value : 0.0\n",
      "Batch size : 189 , Loss value : 0.0\n",
      "Batch size : 62 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 80 , Loss value : 0.0\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 79 , Loss value : 0.0\n",
      "Batch size : 90 , Loss value : 0.0\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 3 , Loss value : 0.0\n",
      "Batch size : 46 , Loss value : 0.0\n",
      "Batch size : 102 , Loss value : 0.0\n",
      "Batch size : 63 , Loss value : 0.0\n",
      "Batch size : 149 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 176 , Loss value : 0.0\n",
      "Batch size : 152 , Loss value : 0.0\n",
      "Batch size : 114 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 40 , Loss value : 0.0\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 71 , Loss value : 0.0\n",
      "Batch size : 58 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 97 , Loss value : 0.0\n",
      "Batch size : 34 , Loss value : 0.0\n",
      "Batch size : 176 , Loss value : 0.0\n",
      "Batch size : 294 , Loss value : 0.0\n",
      "Batch size : 34 , Loss value : 0.0\n",
      "Batch size : 100 , Loss value : 0.0\n",
      "Batch size : 21 , Loss value : 0.0\n",
      "Batch size : 129 , Loss value : 0.0\n",
      "Batch size : 158 , Loss value : 0.0\n",
      "Batch size : 73 , Loss value : 0.0\n",
      "Batch size : 7 , Loss value : 0.0\n",
      "Batch size : 96 , Loss value : 0.0\n",
      "Batch size : 48 , Loss value : 0.0\n",
      "Batch size : 203 , Loss value : 0.0\n",
      "Batch size : 10 , Loss value : 0.0\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 85 , Loss value : 0.0\n",
      "Batch size : 78 , Loss value : 0.0\n",
      "Batch size : 78 , Loss value : 0.0\n",
      "Batch size : 241 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 112 , Loss value : 0.0\n",
      "Batch size : 19 , Loss value : 0.0\n",
      "Batch size : 119 , Loss value : 0.0\n",
      "Batch size : 93 , Loss value : 0.0\n",
      "Batch size : 118 , Loss value : 0.0\n",
      "Batch size : 148 , Loss value : 0.0\n",
      "Batch size : 151 , Loss value : 0.0\n",
      "Batch size : 50 , Loss value : 0.0\n",
      "Batch size : 24 , Loss value : 0.0\n",
      "Batch size : 121 , Loss value : 0.0\n",
      "Batch size : 109 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 58 , Loss value : 0.0\n",
      "Batch size : 30 , Loss value : 0.0\n",
      "Batch size : 116 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 131 , Loss value : 0.0\n",
      "Batch size : 90 , Loss value : 0.0\n",
      "Batch size : 151 , Loss value : 0.0\n",
      "Batch size : 48 , Loss value : 0.0\n",
      "Batch size : 88 , Loss value : 0.0\n",
      "Batch size : 71 , Loss value : 0.0\n",
      "Batch size : 130 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 64 , Loss value : 0.0\n",
      "Batch size : 157 , Loss value : 0.0\n",
      "Batch size : 1 , Loss value : 0.0\n",
      "Batch size : 81 , Loss value : 0.0\n",
      "Batch size : 146 , Loss value : 0.0\n",
      "Batch size : 47 , Loss value : 0.0\n",
      "Batch size : 14 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 132 , Loss value : 0.0\n",
      "Batch size : 169 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 383 , Loss value : 0.0\n",
      "Batch size : 97 , Loss value : 0.0\n",
      "Batch size : 202 , Loss value : 0.0\n",
      "Batch size : 73 , Loss value : 0.0\n",
      "Batch size : 131 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 191 , Loss value : 0.0\n",
      "Batch size : 55 , Loss value : 0.0\n",
      "Batch size : 170 , Loss value : 0.0\n",
      "Batch size : 128 , Loss value : 0.0\n",
      "Batch size : 168 , Loss value : 0.0\n",
      "Batch size : 15 , Loss value : 0.0\n",
      "Batch size : 282 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 247 , Loss value : 0.0\n",
      "Batch size : 247 , Loss value : 0.0\n",
      "Batch size : 12 , Loss value : 0.0\n",
      "Batch size : 64 , Loss value : 0.0\n",
      "Batch size : 124 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 4 , Loss value : 0.0\n",
      "Batch size : 56 , Loss value : 0.0\n",
      "Batch size : 11 , Loss value : 0.0\n",
      "Batch size : 115 , Loss value : 0.0\n",
      "Batch size : 176 , Loss value : 0.00020394447\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 52 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 71 , Loss value : 0.0\n",
      "Batch size : 31 , Loss value : 0.0\n",
      "Batch size : 123 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0002258887\n",
      "Batch size : 247 , Loss value : 4.903608e-05\n",
      "Batch size : 181 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 91 , Loss value : 0.0\n",
      "Batch size : 60 , Loss value : 0.0\n",
      "Batch size : 135 , Loss value : 0.0\n",
      "Batch size : 88 , Loss value : 0.0\n",
      "Batch size : 113 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 52 , Loss value : 0.0\n",
      "Batch size : 123 , Loss value : 0.0\n",
      "Batch size : 92 , Loss value : 0.0\n",
      "Batch size : 5 , Loss value : 0.0\n",
      "Batch size : 50 , Loss value : 0.00022211317\n",
      "Batch size : 55 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 7 , Loss value : 0.0\n",
      "Batch size : 68 , Loss value : 0.0\n",
      "Batch size : 120 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 33 , Loss value : 0.0\n",
      "Batch size : 31 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.00027041597\n",
      "Batch size : 14 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 90 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 89 , Loss value : 0.0001654152\n",
      "Batch size : 38 , Loss value : 0.0\n",
      "Batch size : 160 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 195 , Loss value : 0.0\n",
      "Batch size : 33 , Loss value : 0.0\n",
      "Batch size : 140 , Loss value : 0.0\n",
      "Batch size : 68 , Loss value : 0.0\n",
      "Batch size : 118 , Loss value : 0.0\n",
      "Batch size : 31 , Loss value : 0.0\n",
      "Batch size : 111 , Loss value : 0.0\n",
      "Batch size : 120 , Loss value : 0.0\n",
      "Batch size : 28 , Loss value : 0.0\n",
      "Batch size : 14 , Loss value : 0.0\n",
      "Batch size : 49 , Loss value : 0.0\n",
      "Batch size : 277 , Loss value : 0.0\n",
      "Batch size : 315 , Loss value : 0.0\n",
      "Batch size : 20 , Loss value : 0.0\n",
      "Batch size : 50 , Loss value : 0.0\n",
      "Batch size : 25 , Loss value : 0.0\n",
      "Batch size : 120 , Loss value : 0.0\n",
      "Batch size : 111 , Loss value : 0.0\n",
      "Batch size : 94 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 238 , Loss value : 0.0\n",
      "Batch size : 253 , Loss value : 0.0\n",
      "Batch size : 45 , Loss value : 0.0\n",
      "Batch size : 90 , Loss value : 0.0\n",
      "Batch size : 43 , Loss value : 0.0\n",
      "Batch size : 22 , Loss value : 0.0\n",
      "Batch size : 35 , Loss value : 0.0\n",
      "Batch size : 205 , Loss value : 0.0\n",
      "Batch size : 108 , Loss value : 0.0\n",
      "Batch size : 124 , Loss value : 0.0\n",
      "Batch size : 61 , Loss value : 0.0\n",
      "Batch size : 192 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 131 , Loss value : 0.0003176018\n",
      "Batch size : 62 , Loss value : 0.0\n",
      "Batch size : 106 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 123 , Loss value : 0.0\n",
      "Batch size : 200 , Loss value : 0.0\n",
      "Batch size : 111 , Loss value : 0.0\n",
      "Batch size : 14 , Loss value : 0.0\n",
      "Batch size : 145 , Loss value : 0.0\n",
      "Batch size : 32 , Loss value : 0.0\n",
      "Batch size : 36 , Loss value : 0.0\n",
      "Batch size : 18 , Loss value : 0.0\n",
      "Batch size : 37 , Loss value : 0.0\n",
      "Batch size : 9 , Loss value : 0.0\n",
      "Batch size : 40 , Loss value : 0.0\n",
      "Batch size : 55 , Loss value : 0.0\n",
      "Batch size : 130 , Loss value : 0.0\n",
      "Batch size : 72 , Loss value : 0.0\n",
      "Batch size : 29 , Loss value : 0.0\n",
      "Batch size : 57 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 54 , Loss value : 0.0\n",
      "Batch size : 209 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 101 , Loss value : 0.0\n",
      "Batch size : 144 , Loss value : 0.0\n",
      "Batch size : 204 , Loss value : 0.0\n",
      "Batch size : 84 , Loss value : 0.0\n",
      "Batch size : 169 , Loss value : 0.0\n",
      "Batch size : 99 , Loss value : 0.0\n",
      "Batch size : 48 , Loss value : 0.0\n",
      "Batch size : 66 , Loss value : 0.0\n",
      "Batch size : 353 , Loss value : 0.0\n",
      "Batch size : 231 , Loss value : 0.0\n",
      "Batch size : 23 , Loss value : 0.0\n",
      "Batch size : 8 , Loss value : 0.0\n",
      "Batch size : 35 , Loss value : 0.0\n",
      "Batch size : 51 , Loss value : 0.0\n",
      "Batch size : 31 , Loss value : 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14769/823889272.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"LRCN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# generate embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14769/4227035233.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(features, label)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mFrameSize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFrameSize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFrameSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mFrameSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "factors=np.zeros(Y_train.shape[1])+1.0\n",
    "log_every=1\n",
    "model_name = \"LRCN\"\n",
    "if model_name == \"LRCN\":\n",
    "    model = NeuralNet()\n",
    "else:\n",
    "    model=mymodels.SimpleNet(X_train.shape[1], 30, [X_train.shape[1], 1500, 30])\n",
    "    \n",
    "for epoch in range(100):\n",
    "    # get scheduled values of hyper params\n",
    "    tmargin=0\n",
    "    batch_size=20\n",
    "    lrate=0.001\n",
    "    max_trips=100\n",
    "    max_neg=3\n",
    "    print(\"Epoch \",epoch,(tmargin,batch_size,lrate,max_trips,max_neg))\n",
    "    # define loss and create optimizer\n",
    "    triplet_loss = torch.nn.TripletMarginLoss(margin=tmargin, p=2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lrate)\n",
    "    # get batches\n",
    "    mini_batches=utils.make_batches(X_train, Y_train, batch_size)\n",
    "    loss_values=[]\n",
    "    for batch_num,batch in enumerate(tqdm(mini_batches, leave=False)):\n",
    "        x_batch,y_batch=batch\n",
    "        if model_name == \"LRCN\":\n",
    "        # generate embeddings\n",
    "            xx, yy, fs = prepare_data(x_batch, y_batch)\n",
    "            embeddings = model(torch.tensor(xx.astype('float32')))\n",
    "        else:\n",
    "            embeddings =model(torch.from_numpy(x_batch.astype('float32')))\n",
    "        # generate triplets (online)\n",
    "        trips=utils.get_triplets(embeddings,y_batch,max_neg,max_trips,factors,debug=False)\n",
    "        if trips is None:\n",
    "            continue\n",
    "        anch,pos,neg=trips\n",
    "        # compute loss\n",
    "        loss_batch=triplet_loss(anch,pos,neg)\n",
    "        loss_values.append(loss_batch.detach().numpy())\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss_batch.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        print(\"Batch size :\",anch.shape[0],\", Loss value :\",loss_batch.detach().numpy())\n",
    "    loss_mean=np.mean(np.array(loss_values))\n",
    "    train_acc = get_acc(X_train, Y_train, X_train, Y_train, model, 5, model_name)\n",
    "    val_acc = get_acc(X_train, Y_train, X_val, Y_val, model, 5, model_name)\n",
    "    print(\"\\tTrain Loss for this epoch :\",loss_mean)\n",
    "    print(\"\\tTrain Accuracy for this epoch:\", train_acc)\n",
    "    print(\"\\tValidation Accuracy for this epoch:\", val_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc(X_train, Y_train, X_test, Y_test, model, 1, model_name= model_name)\n",
    "ROC_Score(model, X_test, Y_test,X_train, Y_train, False, model_name= model_name)\n",
    "score_for_each_drug = ROC(model, X_test, Y_test, X_train, Y_train, (\"LRCN\" + \"BO_delete\"), True, model_name= model_name)\n",
    "spec_recall, prec_recall = PR(model, X_test, Y_test, X_train, Y_train ,model_name= model_name)\n",
    "print(\"recall at 95 spec: \", spec_recall)\n",
    "print(\"precision recall: \", prec_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c92d7cf3248ae0e1489a5826981744fa4fc284a54806f658e46833c1635a8328"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
