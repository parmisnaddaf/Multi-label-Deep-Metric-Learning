{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mydatasets\n",
    "import mymodels\n",
    "import utils\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import json \n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3958</th>\n",
       "      <th>3959</th>\n",
       "      <th>3960</th>\n",
       "      <th>3961</th>\n",
       "      <th>3962</th>\n",
       "      <th>3963</th>\n",
       "      <th>3964</th>\n",
       "      <th>3965</th>\n",
       "      <th>3966</th>\n",
       "      <th>3967</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRR1166318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR176810</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR181956</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR2100379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR671746</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR1146372</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR176477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR1049074</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR867528</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7960 rows × 3967 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "0                                                                       ...   \n",
       "SRR1166318     0     0     1     0     0     4     0     0     0     1  ...   \n",
       "ERR176810      0     0     1     0     2     3     0     0     0     1  ...   \n",
       "ERR181956      0     0     1     0     1     3     1     0     0     1  ...   \n",
       "SRR2100379     0     0     1     0     0     4     1     0     0     1  ...   \n",
       "SRR924706      0     0     1     0     2     3     0     0     0     1  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "SRR671746      0     0     1     0     0     3     0     0     0     1  ...   \n",
       "SRR1146372     0     0     2     0     0     3     0     0     0     1  ...   \n",
       "ERR176477      0     0     1     0     1     3     0     0     0     1  ...   \n",
       "SRR1049074     0     0     1     0     0     4     0     0     0     1  ...   \n",
       "ERR867528      0     0     2     0     2     3     0     0     0     2  ...   \n",
       "\n",
       "            3958  3959  3960  3961  3962  3963  3964  3965  3966  3967  \n",
       "0                                                                       \n",
       "SRR1166318     0     0     1     1     0     0     0     0     0     0  \n",
       "ERR176810      0     0     0     1     0     0     0     0     0     0  \n",
       "ERR181956      0     0     0     0     0     0     0     0     0     0  \n",
       "SRR2100379     0     0     0     0     0     0     0     0     0     0  \n",
       "SRR924706      0     0     0     0     0     0     0     0     0     0  \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "SRR671746      0     0     0     0     0     0     0     0     0     0  \n",
       "SRR1146372     0     0     0     0     0     0     0     0     0     0  \n",
       "ERR176477      0     0     0     0     0     0     0     0     0     0  \n",
       "SRR1049074     0     1     0     0     0     0     0     0     0     0  \n",
       "ERR867528      0     0     0     1     0     0     0     0     0     0  \n",
       "\n",
       "[7960 rows x 3967 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('../data/gene_data.csv', header=None, index_col=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amikacin</th>\n",
       "      <th>capreomycin</th>\n",
       "      <th>ciprofloxacin</th>\n",
       "      <th>ethambutol</th>\n",
       "      <th>ethionamide</th>\n",
       "      <th>isoniazid</th>\n",
       "      <th>kanamycin</th>\n",
       "      <th>moxifloxacin</th>\n",
       "      <th>ofloxacin</th>\n",
       "      <th>pyrazinamide</th>\n",
       "      <th>rifampicin</th>\n",
       "      <th>streptomycin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRR3675211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3675215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3675217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3675218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR3675224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924705</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924706</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924707</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924708</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR924709</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7845 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            amikacin  capreomycin  ciprofloxacin  ethambutol  ethionamide  \\\n",
       "id                                                                          \n",
       "SRR3675211       NaN          NaN            NaN         0.0          NaN   \n",
       "SRR3675215       NaN          NaN            NaN         0.0          NaN   \n",
       "SRR3675217       NaN          NaN            NaN         1.0          NaN   \n",
       "SRR3675218       NaN          NaN            NaN         1.0          NaN   \n",
       "SRR3675224       NaN          NaN            NaN         0.0          NaN   \n",
       "...              ...          ...            ...         ...          ...   \n",
       "SRR924705        NaN          0.0            NaN         0.0          0.0   \n",
       "SRR924706        NaN          0.0            NaN         0.0          0.0   \n",
       "SRR924707        NaN          0.0            NaN         0.0          0.0   \n",
       "SRR924708        NaN          0.0            NaN         0.0          0.0   \n",
       "SRR924709        NaN          0.0            NaN         0.0          0.0   \n",
       "\n",
       "            isoniazid  kanamycin  moxifloxacin  ofloxacin  pyrazinamide  \\\n",
       "id                                                                        \n",
       "SRR3675211        0.0        NaN           NaN        NaN           0.0   \n",
       "SRR3675215        0.0        NaN           NaN        NaN           0.0   \n",
       "SRR3675217        1.0        NaN           NaN        NaN           0.0   \n",
       "SRR3675218        1.0        NaN           NaN        NaN           1.0   \n",
       "SRR3675224        0.0        NaN           NaN        NaN           0.0   \n",
       "...               ...        ...           ...        ...           ...   \n",
       "SRR924705         0.0        0.0           NaN        0.0           0.0   \n",
       "SRR924706         0.0        0.0           NaN        0.0           0.0   \n",
       "SRR924707         0.0        0.0           NaN        0.0           0.0   \n",
       "SRR924708         0.0        0.0           NaN        0.0           0.0   \n",
       "SRR924709         0.0        0.0           NaN        0.0           0.0   \n",
       "\n",
       "            rifampicin  streptomycin  \n",
       "id                                    \n",
       "SRR3675211         0.0           NaN  \n",
       "SRR3675215         0.0           NaN  \n",
       "SRR3675217         1.0           NaN  \n",
       "SRR3675218         0.0           NaN  \n",
       "SRR3675224         0.0           NaN  \n",
       "...                ...           ...  \n",
       "SRR924705          0.0           0.0  \n",
       "SRR924706          0.0           0.0  \n",
       "SRR924707          0.0           0.0  \n",
       "SRR924708          0.0           0.0  \n",
       "SRR924709          0.0           0.0  \n",
       "\n",
       "[7845 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.read_csv('../data/AllLabels.csv', index_col='id')\n",
    "Y = Y[Y.index.isin(X.index)]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs with no Y found: 115\n"
     ]
    }
   ],
   "source": [
    "NoYs = X[np.logical_not(X.index.isin(Y.index))]\n",
    "print('Xs with no Y found:', NoYs.shape[0])\n",
    "X = X.drop(NoYs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sort_index().reset_index().rename(columns={0: 'id'})\n",
    "Y = Y.sort_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat = X.iloc[:, 1:].to_numpy()\n",
    "Y_mat = Y.iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Count: 6277\n",
      "Validation Count: 784\n",
      "Test Count: 784\n"
     ]
    }
   ],
   "source": [
    "val_test_count = int(X_mat.shape[0] * 0.1)\n",
    "val_test_indcs = (np.random.permutation(X_mat.shape[0])[:2*val_test_count]).reshape((2, -1))\n",
    "\n",
    "X_val = X_mat[val_test_indcs[0], :]\n",
    "Y_val = Y_mat[val_test_indcs[0], :]\n",
    "\n",
    "X_test = X_mat[val_test_indcs[1], :]\n",
    "Y_test = Y_mat[val_test_indcs[1], :]\n",
    "\n",
    "X_train = np.delete(X_mat, val_test_indcs.flatten(), axis=0)\n",
    "Y_train = np.delete(Y_mat, val_test_indcs.flatten(), axis=0)\n",
    "print(f'Train Count: {X_train.shape[0]}')\n",
    "print(f'Validation Count: {X_val.shape[0]}')\n",
    "print(f'Test Count: {X_test.shape[0]}')\n",
    "\n",
    "shuffle_indcs = np.random.permutation(X_train.shape[0])\n",
    "X_train = X_train[shuffle_indcs, :]\n",
    "Y_train = Y_train[shuffle_indcs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc(x_train: np.ndarray, y_train: np.ndarray, x_eval: np.ndarray, y_eval: np.ndarray, model, n_neighbors=5):\n",
    "    emb_train = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n",
    "    emb_val = model(torch.from_numpy(x_eval.astype('float32'))).detach().numpy()\n",
    "    KNN = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto').fit(emb_train)\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_val)\n",
    "    y_k_neghbors = y_train[nbr_indcs, :]\n",
    "    y_pred = np.nanmean(y_k_neghbors, axis=1)\n",
    "    y_pred[np.where(np.isnan(y_pred))] = 0.5\n",
    "    #y_pred = np.round(y_pred)\n",
    "\n",
    "    condition = np.where(np.logical_and(np.logical_not(np.isnan(y_eval)), np.logical_not(np.isnan(y_pred))))\n",
    "\n",
    "    #### CALCULATE ROC\n",
    "\n",
    "    #return np.sum(y_pred[condition] == y_eval[condition]) / y_eval[condition].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(x_train: np.ndarray, y_train: np.ndarray, x_eval: np.ndarray, y_eval: np.ndarray, model, n_neighbors=5):\n",
    "    emb_train = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n",
    "    emb_val = model(torch.from_numpy(x_eval.astype('float32'))).detach().numpy()\n",
    "    KNN = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto').fit(emb_train)\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_val)\n",
    "    y_k_neghbors = y_train[nbr_indcs, :] #y_eval x 5 x 12\n",
    "    y_pred = np.nanmean(y_k_neghbors, axis=1) #y_eval x 12\n",
    "    y_pred = np.round(y_pred) #0.5 > --> 1\n",
    "\n",
    "    condition = np.where(np.logical_and(np.logical_not(np.isnan(y_eval)), np.logical_not(np.isnan(y_pred))))\n",
    "\n",
    "    return np.sum(y_pred[condition] == y_eval[condition]) / y_eval[condition].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_weighted(x_train: np.ndarray, y_train: np.ndarray, x_eval: np.ndarray, y_eval: np.ndarray, model, n_neighbors=5):\n",
    "    emb_train = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n",
    "    emb_val = model(torch.from_numpy(x_eval.astype('float32'))).detach().numpy()\n",
    "    KNN = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto').fit(emb_train)\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_val)\n",
    "    nbr_weights = np.exp(-nbr_dists)\n",
    "    y_k_neghbors = y_train[nbr_indcs, :] #y_eval x 5 x 12\n",
    "    y_k_neighbors_weighted = y_k_neghbors * nbr_weights.reshape(-1, n_neighbors, 1)\n",
    "    #y_pred = np.nanmean(y_k_neighbors_weighted, axis=1) #y_eval x 12\n",
    "    y_pred = np.nansum(y_k_neighbors_weighted, axis=1) / np.sum(nbr_weights.reshape(-1, n_neighbors, 1), axis=1)\n",
    "    y_pred = np.round(y_pred) #0.5 > --> 1\n",
    "\n",
    "    condition = np.where(np.logical_and(np.logical_not(np.isnan(y_eval)), np.logical_not(np.isnan(y_pred))))\n",
    "\n",
    "    return np.sum(y_pred[condition] == y_eval[condition]) / y_eval[condition].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_per_drug(x_train: np.ndarray, y_train: np.ndarray, x_eval: np.ndarray, y_eval: np.ndarray, model, n_neighbors=5):\n",
    "  emb_train = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n",
    "  emb_val = model(torch.from_numpy(x_eval.astype('float32'))).detach().numpy()\n",
    "  KNN = NearestNeighbors(n_neighbors=5, algorithm='auto').fit(emb_train)\n",
    "\n",
    "  nbr_dists, nbr_indcs = KNN.kneighbors(emb_val)\n",
    "  y_k_neghbors = Y_train[nbr_indcs, :] #y_eval x 5 x 12\n",
    "  y_pred = np.nanmean(y_k_neghbors, axis=1) #y_eval x 12\n",
    "  y_pred = np.round(y_pred) #0.5 > --> 1\n",
    "\n",
    "  acc_per_drug = np.zeros(y_eval.shape[1])\n",
    "  for i in range(y_eval.shape[1]):\n",
    "    condition = np.where(np.logical_and(np.logical_not(np.isnan(y_eval[:, i])), np.logical_not(np.isnan(y_pred[:, i]))))\n",
    "    acc_per_drug[i] = np.sum(y_pred[condition, i] == y_eval[condition, i]) / y_eval[condition, i].shape[1]\n",
    "  return acc_per_drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_per_drug_weighted(x_train: np.ndarray, y_train: np.ndarray, x_eval: np.ndarray, y_eval: np.ndarray, model, n_neighbors=5):\n",
    "    emb_train = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n",
    "    emb_val = model(torch.from_numpy(x_eval.astype('float32'))).detach().numpy()\n",
    "    KNN = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto').fit(emb_train)\n",
    "\n",
    "    nbr_dists, nbr_indcs = KNN.kneighbors(emb_val)\n",
    "    nbr_weights = np.exp(-nbr_dists)\n",
    "    y_k_neghbors = y_train[nbr_indcs, :] #y_eval x 5 x 12\n",
    "    y_k_neighbors_weighted = y_k_neghbors * nbr_weights.reshape(-1, n_neighbors, 1)\n",
    "    #y_pred = np.nanmean(y_k_neighbors_weighted, axis=1) #y_eval x 12\n",
    "    y_pred = np.nansum(y_k_neighbors_weighted, axis=1) / np.sum(nbr_weights.reshape(-1, n_neighbors, 1), axis=1)\n",
    "    y_pred = np.round(y_pred) #0.5 > --> 1\n",
    "\n",
    "    acc_per_drug = np.zeros(y_eval.shape[1])\n",
    "    for i in range(y_eval.shape[1]):\n",
    "        condition = np.where(np.logical_and(np.logical_not(np.isnan(y_eval[:, i])), np.logical_not(np.isnan(y_pred[:, i]))))\n",
    "        acc_per_drug[i] = np.sum(y_pred[condition, i] == y_eval[condition, i]) / y_eval[condition, i].shape[1]\n",
    "    return acc_per_drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(embeddings_tensor, y_batch, max_negatives_per_positive, max_trips_per_anchor, factors):\n",
    "    triplets = []\n",
    "    embeddings = embeddings_tensor.detach().numpy()\n",
    "    num_fine_trips = 0\n",
    "    num_coarse_trips = 0\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        num_anchor_trips = 0\n",
    "        anchor_emb = embeddings[i, :]\n",
    "        anchor_y = y_batch[i, :]\n",
    "\n",
    "        #get similarities\n",
    "        #sim_scores = np.nansum(y_batch * (anchor_y * factors), axis=1) #dot product similarity\n",
    "        sim_scores = utils.my_sim(y_batch, anchor_y, factors) #Equality Similarity\n",
    "\n",
    "        #get embedding distances\n",
    "        distances_emb = np.sqrt(np.sum((embeddings - anchor_emb)**2, axis=1))\n",
    "\n",
    "        #sort similarities w.r.t. distances\n",
    "        sorted_distances_indcs = np.argsort(distances_emb)\n",
    "        similarities_sorted_by_distance = sim_scores[sorted_distances_indcs[:50]]\n",
    "\n",
    "        for pos_sim_limit in reversed(range(y_batch.shape[1])):\n",
    "            if pos_sim_limit == 0: continue\n",
    "            positive_indcs = np.nonzero(similarities_sorted_by_distance == pos_sim_limit)[0]\n",
    "            \n",
    "            for positive_idx in np.flip(positive_indcs):\n",
    "                num_negatives = 0\n",
    "                #Excluding the Anchor\n",
    "                if sorted_distances_indcs[positive_idx] == i:\n",
    "                    continue\n",
    "\n",
    "                positive_similarity = similarities_sorted_by_distance[positive_idx]\n",
    "                \n",
    "                #Points with a lower similarity and also a lower distance\n",
    "                positive_misorderings_condition = np.logical_and(similarities_sorted_by_distance[:positive_idx] < positive_similarity, similarities_sorted_by_distance[:positive_idx] > 0)\n",
    "\n",
    "                for negative_idx in np.nonzero(positive_misorderings_condition)[0]:\n",
    "                    triplets.append((i, sorted_distances_indcs[positive_idx], sorted_distances_indcs[negative_idx]))\n",
    "                    num_anchor_trips += 1\n",
    "                    num_negatives += 1\n",
    "                    num_fine_trips +=1\n",
    "                    if num_negatives > max_negatives_per_positive: break\n",
    "                \n",
    "                if num_anchor_trips >= max_trips_per_anchor: break\n",
    "                zero_condition = np.nonzero(similarities_sorted_by_distance[:positive_idx] == 0)[0]\n",
    "                if len(zero_condition) == 0: continue\n",
    "                num_negatives = np.minimum(zero_condition.shape[0], max_negatives_per_positive)\n",
    "                for _ in range(num_negatives):\n",
    "                    idx = np.random.randint(len(zero_condition))\n",
    "                    zero_idx = zero_condition[idx]\n",
    "                    triplets.append((i, sorted_distances_indcs[positive_idx], sorted_distances_indcs[zero_idx]))\n",
    "                    num_anchor_trips += 1\n",
    "                    num_coarse_trips += 1\n",
    "\n",
    "\n",
    "                if num_anchor_trips >= max_trips_per_anchor: break\n",
    "            if num_anchor_trips >= max_trips_per_anchor: break\n",
    "        \n",
    "    if len(triplets) == 0: return None\n",
    "\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    negatives = []\n",
    "    for (a,p,n) in triplets:\n",
    "        anchors.append(embeddings_tensor[a, :].reshape(1, -1))\n",
    "        positives.append(embeddings_tensor[p, :].reshape(1, -1))\n",
    "        negatives.append(embeddings_tensor[n, :].reshape(1, -1))\n",
    "    \n",
    "    anchors = torch.cat(anchors, dim=0)\n",
    "    positives = torch.cat(positives, dim=0)\n",
    "    negatives = torch.cat(negatives, dim=0)\n",
    "    return anchors, positives, negatives, num_fine_trips, num_coarse_trips, pos_sim_limit\n",
    "                \n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets2(embeddings_tensor, y_batch, max_negatives_per_positive, max_trips_per_anchor, factors):\n",
    "    triplets = []\n",
    "    embeddings = embeddings_tensor.detach().numpy()\n",
    "    num_fine_trips = 0\n",
    "    num_coarse_trips = 0\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        num_anchor_trips = 0\n",
    "        anchor_emb = embeddings[i, :]\n",
    "        anchor_y = y_batch[i, :]\n",
    "\n",
    "        #get similarities\n",
    "        #sim_scores = np.nansum(y_batch * (anchor_y * factors), axis=1) #dot product similarity\n",
    "        sim_scores = utils.my_sim(y_batch, anchor_y, factors) #Equality Similarity\n",
    "\n",
    "        #get embedding distances\n",
    "        distances_emb = np.sqrt(np.sum((embeddings - anchor_emb)**2, axis=1))\n",
    "\n",
    "        #sort similarities w.r.t. distances\n",
    "        sorted_distances_indcs = np.argsort(distances_emb)\n",
    "        similarities_sorted_by_distance = sim_scores[sorted_distances_indcs[:50]]\n",
    "\n",
    "        for pos_sim_limit in reversed(range(y_batch.shape[1])):\n",
    "            if pos_sim_limit == 0: continue\n",
    "            positive_indcs = np.nonzero(similarities_sorted_by_distance == pos_sim_limit)[0]\n",
    "            \n",
    "            for positive_idx in np.flip(positive_indcs):\n",
    "                num_negatives = 0\n",
    "                #Excluding the Anchor\n",
    "                if sorted_distances_indcs[positive_idx] == i:\n",
    "                    continue\n",
    "\n",
    "                positive_similarity = similarities_sorted_by_distance[positive_idx]\n",
    "                \n",
    "                #Points with a lower similarity and also a lower distance\n",
    "                positive_misorderings_condition = np.logical_and(\n",
    "                    similarities_sorted_by_distance[positive_idx:] < positive_similarity,\n",
    "                    distances_emb[sorted_distances_indcs[positive_idx:50]] < distances_emb[sorted_distances_indcs[positive_idx]] + 1,\n",
    "                    similarities_sorted_by_distance[positive_idx:] > 0)\n",
    "\n",
    "                for negative_idx in np.nonzero(positive_misorderings_condition)[0]:\n",
    "                    triplets.append((i, sorted_distances_indcs[positive_idx], sorted_distances_indcs[negative_idx]))\n",
    "                    num_anchor_trips += 1\n",
    "                    num_negatives += 1\n",
    "                    num_fine_trips +=1\n",
    "                    if num_negatives > max_negatives_per_positive: break\n",
    "                \n",
    "                if num_anchor_trips >= max_trips_per_anchor: break\n",
    "                zero_condition = np.nonzero(similarities_sorted_by_distance[:positive_idx] == 0)[0]\n",
    "                if len(zero_condition) == 0: continue\n",
    "                num_negatives = np.minimum(zero_condition.shape[0], max_negatives_per_positive)\n",
    "                for _ in range(num_negatives):\n",
    "                    idx = np.random.randint(len(zero_condition))\n",
    "                    zero_idx = zero_condition[idx]\n",
    "                    triplets.append((i, sorted_distances_indcs[positive_idx], sorted_distances_indcs[zero_idx]))\n",
    "                    num_anchor_trips += 1\n",
    "                    num_coarse_trips += 1\n",
    "\n",
    "\n",
    "                if num_anchor_trips >= max_trips_per_anchor: break\n",
    "            if num_anchor_trips >= max_trips_per_anchor: break\n",
    "        \n",
    "    if len(triplets) == 0: return None\n",
    "\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    negatives = []\n",
    "    for (a,p,n) in triplets:\n",
    "        anchors.append(embeddings_tensor[a, :].reshape(1, -1))\n",
    "        positives.append(embeddings_tensor[p, :].reshape(1, -1))\n",
    "        negatives.append(embeddings_tensor[n, :].reshape(1, -1))\n",
    "    \n",
    "    anchors = torch.cat(anchors, dim=0)\n",
    "    positives = torch.cat(positives, dim=0)\n",
    "    negatives = torch.cat(negatives, dim=0)\n",
    "    return anchors, positives, negatives, num_fine_trips, num_coarse_trips, pos_sim_limit\n",
    "                \n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=mymodels.SimpleNet(X_train.shape[1], 30, [X_train.shape[1], 1500, 30])\n",
    "loss_list = []\n",
    "acc_train_list = []\n",
    "acc_eval_list = []\n",
    "factors=np.zeros(Y_train.shape[1])+1.0\n",
    "log_every=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6738830892827951"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_mat == 0)/np.sum(np.logical_not(np.isnan(Y_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Change the Folder Name\n",
    "# #ONLY Run if you want to load a model\n",
    "# model = torch.load('model.pth')\n",
    "# with open('../FC_weightedKNN_newtrips/lists.list', 'rb') as f:\n",
    "#   loss_list, acc_train_list, acc_eval_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #\n",
       "===================================================================================================================\n",
       "SimpleNet                                --                        --                        --\n",
       "├─ModuleList: 1-1                        --                        --                        --\n",
       "│    └─Linear: 2-1                       [3967, 1500]              [500, 1500]               5,952,000\n",
       "│    └─Linear: 2-2                       [1500, 30]                [500, 30]                 45,030\n",
       "===================================================================================================================\n",
       "Total params: 5,997,030\n",
       "Trainable params: 5,997,030\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.00\n",
       "===================================================================================================================\n",
       "Input size (MB): 7.93\n",
       "Forward/backward pass size (MB): 6.12\n",
       "Params size (MB): 23.99\n",
       "Estimated Total Size (MB): 38.04\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(500,3967), device='cpu', verbose=0, col_names=['kernel_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 (1, 500, 0.001, 100, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/pnaddaf/Desktop/lrcn/final/src/utils.py:24: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sims = np.sum((y_batch * (anchor_y*factors)) == 1, axis=1) / np.sum(np.logical_or((y_batch * (anchor_y*factors)) == 1, (y_batch * (anchor_y*factors))==-1), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size : 35543  - Fine Trips:  21148  - Coarse Trips: 14395  - Last pos limit:  0 ,- Loss value : 1.1006488\n",
      "Below Margin?  472  - Triplet Loss:  1.1006487607955933\n",
      "Batch size : 33740  - Fine Trips:  20460  - Coarse Trips: 13280  - Last pos limit:  1 ,- Loss value : 1.0430931\n",
      "Below Margin?  488  - Triplet Loss:  1.0430930852890015\n",
      "Batch size : 33534  - Fine Trips:  20764  - Coarse Trips: 12770  - Last pos limit:  0 ,- Loss value : 1.022487\n",
      "Below Margin?  669  - Triplet Loss:  1.0224870443344116\n",
      "Batch size : 33416  - Fine Trips:  19952  - Coarse Trips: 13464  - Last pos limit:  1 ,- Loss value : 1.0149903\n",
      "Below Margin?  443  - Triplet Loss:  1.0149903297424316\n",
      "Batch size : 35834  - Fine Trips:  23100  - Coarse Trips: 12734  - Last pos limit:  0 ,- Loss value : 1.0098954\n",
      "Below Margin?  1948  - Triplet Loss:  1.0098954439163208\n",
      "Batch size : 35264  - Fine Trips:  24277  - Coarse Trips: 10987  - Last pos limit:  0 ,- Loss value : 1.008948\n",
      "Below Margin?  1630  - Triplet Loss:  1.0089479684829712\n",
      "Batch size : 34917  - Fine Trips:  23404  - Coarse Trips: 11513  - Last pos limit:  0 ,- Loss value : 1.0087442\n",
      "Below Margin?  1383  - Triplet Loss:  1.008744239807129\n",
      "Batch size : 33980  - Fine Trips:  23785  - Coarse Trips: 10195  - Last pos limit:  0 ,- Loss value : 1.0071958\n",
      "Below Margin?  1546  - Triplet Loss:  1.0071958303451538\n",
      "Batch size : 35799  - Fine Trips:  24302  - Coarse Trips: 11497  - Last pos limit:  1 ,- Loss value : 1.0061991\n",
      "Below Margin?  1814  - Triplet Loss:  1.0061991214752197\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "\t# get scheduled values of hyper params\n",
    "\ttmargin=1\n",
    "\tbatch_size=500\n",
    "\tlrate=0.001\n",
    "\tmax_trips=100\n",
    "\tmax_neg=3\n",
    "\tprint(\"Epoch \",epoch,(tmargin,batch_size,lrate,max_trips,max_neg))\n",
    "\t# define loss and create optimizer\n",
    "\ttriplet_loss = torch.nn.TripletMarginLoss(margin=tmargin, p=2)\n",
    "\ttriplet_loss2 = torch.nn.TripletMarginLoss(margin=tmargin, p=2, reduction='none')\t\n",
    "\toptimizer = torch.optim.Adam(model.parameters(),lr=lrate)\n",
    "\t# get batches\n",
    "\tmini_batches=utils.make_batches(X_train, Y_train, batch_size)\n",
    "\tloss_values=[]\n",
    "\tfor batch_num,batch in enumerate(mini_batches):\n",
    "\t\tx_batch,y_batch=batch\n",
    "\t\t# generate embeddings\n",
    "\t\tembeddings=model(torch.from_numpy(x_batch.astype('float32')))\n",
    "\t\t# generate triplets (online)\n",
    "\t\ttrips=get_triplets2(embeddings,y_batch,max_neg,max_trips,factors)\n",
    "\t\t# trips=utils.get_triplets(embeddings,y_batch,max_neg,max_trips,factors,debug=False)\n",
    "\t\tif trips is None:\n",
    "\t\t\tcontinue\n",
    "\t\t# anch, pos, neg=trips\n",
    "\t\tanch, pos, neg, num_fine_trips, num_coarse_trips, last_pos_sim_limit=trips\n",
    "\t\t# compute loss\n",
    "\t\tloss_triplet=triplet_loss(anch,pos,neg)\n",
    "\t\t#loss_var = (1 - torch.mean(torch.var(embeddings, dim=1)))**2\n",
    "\t\tloss_batch = loss_triplet\n",
    "\t\tloss_batch2=triplet_loss2(anch,pos,neg).detach()\n",
    "\t\tloss_values.append(loss_batch.detach().numpy())\n",
    "\t\t# backprop\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss_batch.backward(retain_graph=True)\n",
    "\t\toptimizer.step()\n",
    "\t\tprint(\"Batch size :\",anch.shape[0],\" - Fine Trips: \",num_fine_trips, \" - Coarse Trips:\", num_coarse_trips,\" - Last pos limit: \",last_pos_sim_limit,\",- Loss value :\",loss_batch.detach().numpy())\n",
    "\t\tprint(\"Below Margin? \", torch.sum(loss_batch2 < tmargin).item(), \" - Triplet Loss: \", loss_triplet.item())\n",
    "\t\t# print(\"Batch size :\",anch.shape[0],\",- Loss value :\",loss_batch.detach().numpy())\n",
    "\tloss_mean=np.mean(np.array(loss_values))\n",
    "\ttrain_acc = get_acc_weighted(X_train, Y_train, X_train, Y_train, model, n_neighbors=5)\n",
    "\tval_acc = get_acc_weighted(X_train, Y_train, X_val, Y_val, model, n_neighbors=5)\n",
    "\tloss_list.append(loss_mean)\n",
    "\tacc_train_list.append(train_acc)\n",
    "\tacc_eval_list.append(val_acc)\n",
    "\tprint(\"\\tTrain Loss for this epoch :\",loss_mean)\n",
    "\tprint(\"\\tTrain Accuracy for this epoch:\", train_acc)\n",
    "\tprint(\"\\tValidation Accuracy for this epoch:\", val_acc)\n",
    "\n",
    "\tif (epoch+1)%5 == 0:\n",
    "\t\t#Change Folder Name\n",
    "\t\ttorch.save(model, '../test/model.pth')\n",
    "\t\twith open('../test/lists.list', 'wb') as f:\n",
    "\t\t\tpickle.dump((loss_list, acc_train_list, acc_eval_list), f)\n",
    "\t\tprint('model saved!')\n",
    "\n",
    "\tif (epoch+1)%log_every==0:\n",
    "\t\tutils.log_epoch_metrics('t.txt',epoch,loss_mean,model,X_train,Y_train,X_val,Y_val,5)\n",
    "\tprint('='*60)\n",
    "\t# # evaluate model\n",
    "\t# if (epoch+1)%checkpoint_every==0:\n",
    "\t# \ttorch.save(model,args[\"run_dir\"]+\"/model_\"+str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_weighted(X_train, Y_train, X_test, Y_test, model, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(loss_list))\n",
    "y = np.array(loss_list)\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.array(acc_train_list))\n",
    "ax.plot(x, np.array(acc_eval_list))\n",
    "ax.set_ylim((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_drug = get_acc_per_drug(X_train, Y_train, X_val, Y_val, model, 5)\n",
    "acc_per_drug_test = get_acc_per_drug(X_train, Y_train, X_test, Y_test, model, 5)\n",
    "drug_names = Y.columns[1:].to_numpy()\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(drug_names.shape[0])\n",
    "ax.plot(x, acc_per_drug)\n",
    "ax.plot(x, acc_per_drug_test)\n",
    "ax.set_xticks(x)\n",
    "ax.set_ylim((0,1.1))\n",
    "ax.set_xticklabels(drug_names, rotation=70)\n",
    "ax.legend(['eval', 'test'])\n",
    "fig.set_size_inches((12,7))\n",
    "fig.set_facecolor('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sim_count(\n",
    "        X_plt, Y_plt, trained_model, untrained_model, inter_threshold=5, intra_threshold=0, max_points_per_sim=1, weighted_radius=False, custom_anchor_idx=None,\n",
    "        colors = ['bisque', 'forestgreen', 'slategrey', 'royalblue', 'lawngreen', 'red', 'magenta', 'cyan', 'gold', 'lime', 'peru', 'indigo']\n",
    "    ):\n",
    "    if custom_anchor_idx is not None:\n",
    "        maxi = custom_anchor_idx\n",
    "        maxlen = np.unique(np.sum(Y_plt == Y_plt[maxi], axis=1)).shape[0]\n",
    "        print('Custom Anchor:')\n",
    "        print(f'Max Similarity Count: {maxlen}')\n",
    "        print(f'Custom Anchor Index: {maxi}')\n",
    "    else:\n",
    "        # Find a good anchor\n",
    "        maxlen = 0\n",
    "        maxi = 0\n",
    "        Y_plt_maskable = np.ma.array(Y_plt, mask=False)\n",
    "        for i in tqdm(range(Y_plt.shape[0])):\n",
    "            Y_plt_maskable.mask[i] = True\n",
    "            sim_uniq, sim_counts = np.unique(np.sum(Y_plt_maskable == Y_plt[i], axis=1), return_counts=True)\n",
    "            sim_uniq = sim_uniq.compressed()\n",
    "            if maxlen < sim_uniq.shape[0] and np.all(sim_counts[:-1] > 10):\n",
    "                maxlen = sim_uniq.shape[0]\n",
    "                maxi = i\n",
    "            Y_plt_maskable.mask[i] = False\n",
    "        print(f'Max Similarity Count: {maxlen}')\n",
    "        print(f'Best Anchor Index: {maxi}')\n",
    "\n",
    "\n",
    "    #Seperate each similarity count\n",
    "    sim_list_indcs = []\n",
    "    for i in range(maxlen):\n",
    "        sim_list_indcs.append(np.where(np.sum(Y_plt == Y_plt[maxi], axis=1) == i)[0])\n",
    "\n",
    "\n",
    "    #TSNE\n",
    "    emb_plt = trained_model(torch.from_numpy(X_plt.astype('float32'))).detach().numpy()\n",
    "    tsne_plt = TSNE(n_components=2, metric='euclidean').fit_transform(emb_plt)\n",
    "\n",
    "    # Sort indcs w.r.t. their distance from anchor\n",
    "    for i in range(maxlen): \n",
    "        criteria = np.argsort(np.linalg.norm(tsne_plt[sim_list_indcs[i]] - tsne_plt[maxi], axis=1))\n",
    "        sim_list_indcs[i] = sim_list_indcs[i][criteria]\n",
    "\n",
    "    #Calculate points radius\n",
    "    if weighted_radius:\n",
    "        radius = [sim.shape[0] for sim in sim_list_indcs]\n",
    "        radius = np.array(radius) / np.sum(radius) * 100000\n",
    "    else:\n",
    "        radius = [150 for sim in sim_list_indcs]\n",
    "\n",
    "\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    #prev_norm = np.linalg.norm(tsne_plt[sim_list_indcs[-1][1]] - tsne_plt[maxi]) - inter_threshold\n",
    "    prev_norm = 0.01\n",
    "    ax.scatter(tsne_plt[maxi, 0], tsne_plt[maxi, 1], s=150)\n",
    "    ax.annotate('A', (tsne_plt[maxi, 0], tsne_plt[maxi, 1]), fontsize= 20)\n",
    "    selected_points_dict = {'A': (maxi, X.iloc[maxi, 0])}\n",
    "    for i in reversed(range(maxlen)):\n",
    "        for j in range(sim_list_indcs[i].shape[0]):\n",
    "            current_norm = np.linalg.norm(tsne_plt[sim_list_indcs[i][j]] - tsne_plt[maxi])\n",
    "            if current_norm >= prev_norm + inter_threshold:\n",
    "                prev_norm = current_norm\n",
    "                current_centroid = tsne_plt[sim_list_indcs[i][j]]\n",
    "                selected_points_dict[i] = (sim_list_indcs[i][j], X.iloc[sim_list_indcs[i][j], 0])\n",
    "                point_count = 0\n",
    "                while intra_threshold >= np.linalg.norm(tsne_plt[sim_list_indcs[i][j]] - current_centroid) and point_count < max_points_per_sim:\n",
    "                    ax.scatter(tsne_plt[sim_list_indcs[i][j], 0], tsne_plt[sim_list_indcs[i][j], 1], s=150, c=colors[i])\n",
    "                    ax.annotate(str(i), (tsne_plt[sim_list_indcs[i][j], 0], tsne_plt[sim_list_indcs[i][j], 1]), fontsize=20)\n",
    "                    point_count += 1\n",
    "                    j += 1\n",
    "                    if j == sim_list_indcs[i].shape[0]: break\n",
    "                break\n",
    "\n",
    "    fig.set_facecolor('w')\n",
    "    fig.set_size_inches((15,10))\n",
    "    fig.savefig('tsne_trained.png', dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "    ####### plot the same points with no train\n",
    "    #TSNE\n",
    "    emb_plt = untrained_model(torch.from_numpy(X_plt.astype('float32'))).detach().numpy()\n",
    "    tsne_plt = TSNE(n_components=2, metric='euclidean').fit_transform(emb_plt)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    #prev_norm = np.linalg.norm(tsne_plt[sim_list_indcs[-1][1]] - tsne_plt[maxi]) - inter_threshold\n",
    "    for key in selected_points_dict.keys():\n",
    "        idx = selected_points_dict[key][0]\n",
    "        ax.scatter(tsne_plt[idx, 0], tsne_plt[idx, 1], s=150, c=colors[key if key != 'A' else -1])\n",
    "        ax.annotate(str(key), (tsne_plt[idx, 0], tsne_plt[idx, 1]), fontsize=20)\n",
    "\n",
    "    fig.set_facecolor('w')\n",
    "    fig.set_size_inches((15,10))\n",
    "    fig.savefig('tsne_untrained.png', dpi=300)\n",
    "\n",
    "    return selected_points_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained = mymodels.SimpleNet(X_train.shape[1], 30, [X_train.shape[1], 1500, 30])\n",
    "plot_sim_count(\n",
    "    X_mat,\n",
    "    Y_mat,\n",
    "    model,\n",
    "    untrained,\n",
    "    inter_threshold=5,\n",
    "    intra_threshold=0,\n",
    "    max_points_per_sim=1,\n",
    "    weighted_radius=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROTOTYPE CODE - NO NEED TO RUN ANYTHING BELOW THIS TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 0\n",
    "maxi = 0\n",
    "Y_train_maskable = np.ma.array(Y_mat, mask=False)\n",
    "for i in tqdm(range(Y_mat.shape[0])):\n",
    "    Y_train_maskable.mask[i] = True\n",
    "    sim_uniq, sim_counts = np.unique(np.sum(Y_train_maskable == Y_mat[i], axis=1), return_counts=True)\n",
    "    sim_uniq = sim_uniq.compressed()\n",
    "    if maxlen < sim_uniq.shape[0] and np.all(sim_counts[:-1] > 10):\n",
    "        maxlen = sim_uniq.shape[0]\n",
    "        maxi = i\n",
    "    Y_train_maskable.mask[i] = False\n",
    "\n",
    "print(f'Max Similarity Count: {maxlen}')\n",
    "print(f'Best Anchor Index: {maxi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list_indcs = []\n",
    "for i in range(maxlen):\n",
    "    sim_list_indcs.append(np.where(np.sum(Y_mat == Y_mat[maxi], axis=1) == i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mat[1514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train = model(torch.from_numpy(X_mat.astype('float32'))).detach().numpy()\n",
    "tsne_train = TSNE(n_components=2, metric='euclidean').fit_transform(emb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(maxlen): \n",
    "    criteria = np.argsort(np.linalg.norm(tsne_train[sim_list_indcs[i]] - tsne_train[maxi], axis=1))\n",
    "    sim_list_indcs[i] = sim_list_indcs[i][criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = [sim.shape[0] for sim in sim_list_indcs]\n",
    "radius = np.array(radius) / np.sum(radius) * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(tsne_train[sim_list_indcs[11]] - tsne_train[maxi], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.tensor(X_mat[[maxi]].astype('float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmm = copy.deepcopy(model)\n",
    "for layer in mmmm.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "threshold = 5\n",
    "prev_norm = np.linalg.norm(tsne_train[sim_list_indcs[-1][1]] - tsne_train[maxi]) - threshold\n",
    "prev_norm = 0.01\n",
    "threshold2 = 0\n",
    "max_points = 1\n",
    "colors = ['bisque', 'forestgreen', 'slategrey', 'royalblue', 'lawngreen', 'red', 'magenta', 'cyan', 'gold', 'lime', 'peru', 'indigo']\n",
    "ax.scatter(tsne_train[maxi, 0], tsne_train[maxi, 1], s=150)\n",
    "ax.annotate('A', (tsne_train[maxi, 0], tsne_train[maxi, 1]), fontsize= 20)\n",
    "selected_points_dict = {'A': X.iloc[maxi, 0]}\n",
    "for i in reversed(range(maxlen)):\n",
    "    for j in range(sim_list_indcs[i].shape[0]):\n",
    "        current_norm = np.linalg.norm(tsne_train[sim_list_indcs[i][j]] - tsne_train[maxi])\n",
    "        if current_norm >= prev_norm + threshold:\n",
    "            prev_norm = current_norm\n",
    "            current_centroid = tsne_train[sim_list_indcs[i][j]]\n",
    "            selected_points_dict[i] = X.iloc[sim_list_indcs[i][j], 0]\n",
    "            point_count = 0\n",
    "            while threshold2 >= np.linalg.norm(tsne_train[sim_list_indcs[i][j]] - current_centroid) and point_count < max_points:\n",
    "                ax.scatter(tsne_train[sim_list_indcs[i][j], 0], tsne_train[sim_list_indcs[i][j], 1], s=150, c=colors[i])\n",
    "                ax.annotate(str(i), (tsne_train[sim_list_indcs[i][j], 0], tsne_train[sim_list_indcs[i][j], 1]), fontsize=20)\n",
    "                point_count += 1\n",
    "                j += 1\n",
    "                if j == sim_list_indcs[i].shape[0]:\n",
    "                    break\n",
    "            break\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "fig.set_size_inches((15,10))\n",
    "fig.savefig('tsne.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(tsne_train[maxi, 0], tsne_train[maxi, 1], s=300, c='black')\n",
    "ax.annotate('A', (tsne_train[maxi, 0], tsne_train[maxi, 1]), fontsize= 30)\n",
    "colors = ['bisque', 'forestgreen', 'slategrey', 'royalblue', 'purple', 'red', 'magenta', 'cyan', 'gold', 'lime', 'peru', 'indigo']\n",
    "for i in range(maxlen):        \n",
    "    ax.scatter(tsne_train[sim_list_indcs[i][:], 0], tsne_train[sim_list_indcs[i][:], 1], s=20, c=colors[i])\n",
    "    #ax.annotate(str(i), (tsne_train[sim_list_indcs[i][0], 0], tsne_train[sim_list_indcs[i][0], 1]), fontsize=20)\n",
    "ax.legend([str(i) for i in range(maxlen)])\n",
    "fig.set_size_inches((15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c92d7cf3248ae0e1489a5826981744fa4fc284a54806f658e46833c1635a8328"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
